# 学习总结

## 微服务

1、服务发现——Netflix Eurek

该系统下还分为Eureka服务端和Eureka客户端，Eureka服务端用作服务注册中心，支持集群部署。Eureka客户端是一个java客户端，用来处理服务注册与发现

2、客服端负载均衡——Netflix Ribbon

基于Http和Tcp的客户端负载均衡，使得面向REST请求时变换为客户端的负载服务调用，提供客户端的软件负载均衡算法。

3、断路器——Netflix Hystrix

它的作用是保护系统，控制故障范围。

1. 服务降级(fallback)

服务器忙，请稍后再试，不让客户端等待并立刻返回一个友好提示，fallback

哪些情况会出发降级

程序运行导常
超时
服务熔断触发服务降级
线程池/信号量打满也会导致服务降级
2. 服务熔断(break)

类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示。

服务的降级 -> 进而熔断 -> 恢复调用链路

3. 服务限流(flowlimit)

秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟N个，有序进行。


4、服务网关——**Spring Cloud Gateway** 

提供api网关，路由，负载均衡等作用；API 网关是一个搭建在客户端和微服务之间的服务，我们可以在 API 网关中处理一些非业务功能的逻辑，例如权限验证、监控、缓存、请求路由等 

网关最基本的模块。它由一个 ID、一个目标 URI、一组断言（Predicate）和一组过滤器（Filter）组成。 

```
filter里数据量大偶发乱码问题解决：
public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
 DataBufferFactory bufferFactory = originalResponse.bufferFactory();
        ServerHttpResponseDecorator decoratedResponse = new ServerHttpResponseDecorator(originalResponse) {
            @Override
            public Mono<Void> writeWith(Publisher<? extends DataBuffer> body) {
             if (body instanceof Flux) {
                    Flux<? extends DataBuffer> fluxBody = (Flux<? extends DataBuffer>) body;
                    return super.writeWith(fluxBody.buffer().map(dataBuffers -> {//解决返回体分段传输
                    
                    //如果响应过大，会进行截断，出现乱码，然后看api DefaultDataBufferFactory有个join方法可以合并所有的流，乱码的问题解决
                        DataBufferFactory dataBufferFactory = new DefaultDataBufferFactory();
                        DataBuffer join = dataBufferFactory.join(dataBuffers);
                        byte[] content = new byte[join.readableByteCount()];
                        join.read(content);
                        //释放掉内存
                        DataBufferUtils.release(join);
                        //组装apiLog对象，用于记录api请求日志
                        String result = new String(content, StandardCharsets.UTF_8);
                        //---end
```

5、分布式配置——Spring Cloud Config

提供服务端和客户端，服务器存储后端的默认实现使用git

Spring Cloud Feign 是一个声明web服务客户端，这使得编写Web服务客户端更容易，使用Feign 创建一个接口并对它进行注解 

Zipkin是一个分布式跟踪系统。它有助于收集解决服务架构中延迟问题所需的计时数据。特性包括此数据的收集和查找。 

 Spring Cloud Sleuth：分布式跟踪实现， 可以完美整合Zipkin。

#### 认证授权方案

https://blog.csdn.net/qq_42046105/article/details/124919245

**客户端Token+网关**

![a8d0af05e8cf2b6981b3b848248f2afa.png](https://img-blog.csdnimg.cn/img_convert/a8d0af05e8cf2b6981b3b848248f2afa.png) 

客户端Token是一种比较常用的认证方案，有点在于Token中携带了用户信息在服务之间传输，做到了无状态，可以通过JWT等安全机制加密Token保证Token的安全性

- 客户端发起认证请求，使用JWT等加密方式生成安全的 Token，Token中携带了认证授权信息，然后返回给客户端，
- 客户端存储Token，后续客户端需要访问资源时，携带者Token请求。
- 客户端发起请求，在网关层对Token进行统一检查，检查通过Token继续携带到后端访问中如果涉及到大量的用户信息的存放，可以使用Redis来进行存储。
- 后续服务获取到Token即可获取到用户信息

客户端Token方案的好处在于可以做到无状态，因为Token中包含了用户信息，服务端不用考虑存储用户信息，缺点在于Token过长造成的网络传输的开销。  

**Spring Cloud Security** 



**ES=elaticsearch** **分布式全文检索引擎** 

https://blog.csdn.net/promsing/article/details/122876032

跟mysql类似，一个实体类、一个库操作接口类、 ElasticsearchTemplate elasticsearchTemplate 



## MQ

[消息队列](https://so.csdn.net/so/search?q=%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97&spm=1001.2101.3001.7020)中间件是分布式系统中重要的组件，主要解决异步消息，应用解耦，流量削锋和消息通讯四个场景等问题，实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ 

1.异步消息：用户注册后，异步发注册邮件和注册短信 

2.应用解耦：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口 ；假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，订单系统与库存系统耦合 

订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功 库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作 

3.流量削锋：秒杀或团抢活动中 ，用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。

4.日志处理是指将消息队列用在日志处理中，比如[Kafka](https://so.csdn.net/so/search?q=Kafka&spm=1001.2101.3001.7020)的应用，解决大量日志传输的问题。架构简化如下 



**RocketMQ(阿里开源)写入性能上不如kafka, 主要因为kafka主要应用于日志场景，而RocketMQ应用于业务场景，为了保证消息必达牺牲了性能，且基于线上真实场景没有在RocketMQ层做消息合并，推荐在业务层自己做。** 

RocketMQ是消息中间件，kafka是分布式流式系统，提供了可靠的顺序保证 。 

Kafka 为每个主题维护一个消息分区日志。每个分区都是由有序的不可变的记录序列组成，并且消息都是连续的被追加在尾部。 

生产者可以向一个具体的主题发送消息，然后多个消费者组可以消费相同的消息。每一个消费者组都可以独立的伸缩去处理相应的负载。由于消费者维护自己的分区偏移，所以他们可以选择持久订阅或者临时订阅，持久订阅在重启之后不会丢失偏移而临时订阅在重启之后会丢失偏移并且每次重启之后都会从分区中最新的记录开始读取。 

##### 如何保证消息不丢失

https://blog.csdn.net/Weixiaohuai/article/details/124496915

##### RocketMQ

一、Producer保证消息不丢失

1、RocketMQ发送消息有三种模式，即同步发送，异步发送、单向发送。

同步发送消息时会同步阻塞等待Broker返回发送结果，如果发送失败不会收到发送结果SendResult,这种是最可靠的发送方式。
异步发送消息可以在回调方法中得知发送结果。
单向发送是消息发送完之后就不管了，不管发送成功没成功，是最不可靠的一种方式 

生产者的重试机制 

mq为生产者提供了失败重试机制，同步发送和异步发送默认都是失败重试两次当然可以修改重试次数，如果多次还是失败，那么可以采取记录这条信息，然后人工采取补偿机制。 

**二、Broker保证消息不丢失**

Broker 是 RocketMQ 的核心, 大部分“重量级”工作都是由 Broker 完成的, 包括接收 Producer 发过来的消息、处理 Consumer 的消费消息请求、消息的持久化存储、以及服务端过滤功能等

1、刷盘策略

RocketMq持久化消息有两种策略即同步刷盘和异步刷盘。默认情况下是异步刷盘，此模式下当生产者把消息发送到broker，消息存到内存之后就认为消息发送成功了，就会返回给生产者消息发送成功的结果。但是如果消息还没持久化到硬盘，服务器宕机了，那么消息就会丢失。同步刷盘是当Broker接收到消息并且持久化到硬盘之后才会返回消息发送成功的结果，这样就会保证消息不会丢失，但是同步刷盘相对于异步刷盘来说效率上有所降低，大概降低10% 

集群模式

rocketmq的集群模式保证可rocketMQ高可用。利用多master多slave节点保证rocketmq的高可用；此模式是broker保证消息不丢失的配置，主从复制同步复制，刷盘模式同步刷盘，但是这种模式下性能会有所降低 

三、**Consumer保证消息不丢失** 

(1)、消费重试机制
消费者从RocketMQ拉取到消息之后，需要返回消费成功来表示业务方正常消费完成。因此只有返回CONSUME_SUCCESS才算消费完成，如果返回CONSUME_LATER则会按照不同的messageDelayLevel时间进行再次消费，时间分级从秒到小时，最长时间为2个小时后再次进行消费重试，如果消费满16次之后还是未能消费成功，则不再重试，会将消息发送到死信队列，从而保证消息存储的可靠性。

(2)、死信队列
未能成功消费的消息，消息队列并不会立刻将消息丢弃，而是将消息发送到死信队列，其名称是在原队列名称前加%DLQ%，如果消息最终进入了死信队列，则可以通过RocketMQ提供的相关接口从死信队列获取到相应的消息，保证了消息消费的可靠性。 

###### 消息过滤

RocketMQ支持两种消息过滤方式：一种是RocketMQ自带的Tag、SQL92过滤，在消费者订阅Topic的时候指定Tag或SQL92表达式；另一种是FilterServer机制，需要上传自定义的ClassFilter类至Broker所在的服务器，Consumer从FilterServer拉取消息，FilterServer负责将请求转发给Broker并从Broker获取消息后根据上传的Java程序做过滤，将过滤后的消息返回给Consumer，FilterServer机制可以充分利用Broker所在服务器的CPU减少网卡流量，且用Java程序写过滤逻辑比较灵活，但要注意代码的质量，避免过渡消耗Broker所在服务器的CPU跟内存。灰度发布一般灰度规则不会太复杂，使用Tag或SQL92过滤即可。 

Tag过滤和SQL过滤 ：

Tag过滤机制，首先会在Broker上对Tag做一次hash值过滤，将不必要的消息过滤出去，不让Consumer拉取，减轻网络传输的压力，为避免因Hash冲突造成的过滤不全的问题，再在客户端做一次按内容匹配的过滤。 

SQL92过滤机制，需要设置属性enablePropertyFilter=true，与Tag不同，sql过滤逻辑只在Broker上 

 **顺序消费**

顺序发送：

通过一定算法，将一组顺序消息发送到同一个broker下面的同一个队列，消费者进行顺序监听即可。

```
// RocketMQ通过MessageQueueSelector中实现的算法来确定消息发送到哪一个队列上
// RocketMQ默认提供了两种MessageQueueSelector实现：随机/Hash
// 当然你可以根据业务实现自己的MessageQueueSelector来决定消息按照何种策略发送到消息队列中
SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
    @Override
    public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
        Integer id = (Integer) arg;
        int index = id % mqs.size();
        return mqs.get(index);
    }
}, orderId);
```



###### 消息堆积

     消息堆积常见于以下几种情况：

（1）新上线的消费者功能有BUG，消息无法被消费。

（2）消费者实例宕机或因网络问题暂时无法同Broker建立连接。

（3）生产者短时间内推送大量消息至Broker，消费者消费能力不足。

（4）生产者未感知Broker消费堆积持续向Broker推送消息。
————————————————
原文链接：https://blog.csdn.net/weixin_43506048/article/details/121051405



**消费过程幂等**

 RocketMQ无法避免消息重复（Exactly-Once），所以如果业务对消费重复非常敏感，务必要在业务层面进行去重处理。可以借助关系数据库进行去重 

 

##### Elastic Search （聚合查询)

Elastic Search基于lucene，**封装**了许多**lucene**底层功能，提供了分布式的服务、简单易用的restful API接口和许多语言的客户端。

聚合：英文为Aggregation，是es除搜索功能外提供的针对es数据做统计分析的功能。聚合有助于根据搜索查询提供聚合数据。聚合查询是数据库中重要的功能特性，ES作为搜索引擎兼数据库，同样提供了强大的聚合分析能力。它基于查询条件来对数据进行分桶、计算的方法。有点类似于 SQL 中的 group by 再加一些函数方法的操作。

注意事项：text类型是不支持聚合的。 

```
https://blog.csdn.net/wen262856298/article/details/124064768
AggregationBuilders
```

## Mybatis

#### 工作原理



## 缓存

##### 穿透 击穿 雪崩

1、缓存穿透
缓存穿透：指在redis缓存中不存在数据，这个时候只能去访问持久层数据库，当用户很多时，缓存都没有命中就会照成很大压力
解决方案 ：
（1）布隆过滤器（对可能查询的数据先用hash存储）
（2）缓存空对象：在没有的数据中存一个空，而这些空的对象会设置一个有效期）

2、缓存击穿
缓存击穿：指在同一个时间内访问一个请求的请求数过多，而在这个时候缓存某个key失效了，这个时候就会冲向数据库照成缓存击穿
解决方案：
（1）设置缓存永远不过期
（2）加互斥锁，使用分布式锁，保证每个key只有一个线程去查询后端服务，而其他线程为等待状态。这种模式将压力转到了分布式锁上

3、缓存雪崩
缓存雪崩：在某个时间段，缓存集体过期、redis宕机、增加删除节点导致
解决方案：给key的失效时间设置为随机时间，避免集体过期；双缓存；加互斥锁

原文链接：https://blog.csdn.net/weixin_44975592/article/details/126287594





## Mysql

##### B+树

![img](https://img-blog.csdnimg.cn/img_convert/398aa23eb83e3170d7a41da31b2c8ddd.png) 

1、B+树的所有数据都存储在叶子节点，非叶子节点只存储索引。

2、叶子节点中的数据使用双向链表的方式进行关联。

2、原因分析
我认为，MySQL索引结构采用B+树，有以下4个原因：

1、从磁盘I/O效率方面来看：B+树的非叶子节点不存储数据，所以树的每一层就能够存储更多的索引数量，也就是说，B+树在层高相同的情况下，比B树的存储数据量更多，间接会减少磁盘I/O的次数。

2、从范围查询效率方面来看：在MySQL中，范围查询是一个比较常用的操作，而B+树的所有存储在叶子节点的数据使用了双向链表来关联，所以B+树在查询的时候只需查两个节点进行遍历就行，而B树需要获取所有节点，因此，B+树在范围查询上效率更高。

3、从全表扫描方面来看：因为，B+树的叶子节点存储所有数据，所以B+树的全局扫描能力更强一些，因为它只需要扫描叶子节点。而B树需要遍历整个树。

4、从自增ID方面来看：基于B+树的这样一种数据结构，如果采用自增的整型数据作为主键，还能更好的避免增加数据的时候，带来叶子节点分裂导致的大量运算的问题。

（B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。如果插入的值比最大值id大，则只需要最后记录后面插入一个新记录。如果新插入的ID值在原先的有序中间，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。如果所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。
除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。

2.存储空间来说，**主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。** 如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节 。
————————————————
原文链接：https://blog.csdn.net/qq_35427589/article/details/124051662）

————————————————
原文链接：https://blog.csdn.net/gupaoedu_tom/article/details/125018395

##### 联合索引的底层结构

**必须有第一个索引字段存在才走索引，可以=也可以范围。**

![在这里插入图片描述](https://img-blog.csdnimg.cn/5f5abd674df046edad4832eab77679a2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbGl1X3NoaV9qdW4=,size_20,color_FFFFFF,t_70,g_se,x_16) 

索引长度计算方法
计算规则
1.索引字段，没有设置NOT NULL，需要占用一个字节。NULL在mysql中是用一个标志位来表示的，用一个字节,null也走索引，并且排在索引的最前面。并不是有些说法说的那样不走索引的
2.定长字段：tinyiny占1个字节、int占4个字节、bitint占8个字节、date占3个字节、datetime占5个字节，char(n)占n个字符。
3.变长字段：varchar(n)占n个字符+2个字节。
4.不同的字符集，一个字符占用的字节数不同：

latin1编码，每个字符占用一个字节
gbk编码，每个字符占用两个字节
utf8编码，每个字符占用三个字节
utf8mb4编码，每个字符占用四个字节

explain select  * from city where  population = 731200  and name = '3' and district = '12'

像上面的例子，我用的是utf8编码，并且没有设置不可为null。
name索引长度： 2553+2+1=768 （null标志位占一个字节）
age索引长度：4+1=5 （null标志位占一个字节）
position索引长度： 2553+2+1=768 （null标志位占一个字节）
————————————————
原文链接：https://blog.csdn.net/liu_shi_jun/article/details/123132731

**不走索引**：列做了显性或隐性的类型转换、使用函数、使用'%**'开头、没有使用第一个列、使用了！=或is not null 、范围查询会导致其后边的列不走索引、某列没出现会导致它及以后的都不走索引

**在MySQL中，支持两种排序方式，分别是FileSort和Index排序。**

- Index排序中，索引可以保证数据的有序性，不需要再进行排序，效率更好。

- FileSort排序则一般在内存中进行排序，占用CPU较多。如果待排结果较大，会产生临时文件IO到磁盘进行排序的情况，效率较低。

  order by 不走索引问题：1.强制索引 FORCE INDEX（key） 2.联合索引

##### 回表的含义

**根据非主键索引查询到的结果并没有查找的字段值，此时就需要再次根据主键从聚簇索引（主键索引）的根节点开始查找，这样再次查找到的记录才是完成的。** 

如果查询结果中只是索引的字段，则不需要回表。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200616160842582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ptZW1vcnlz,size_16,color_FFFFFF,t_70) 

问题：

1. 为什么非主键索引结构叶子节点存储的是主键值？

​     一是保证一致性，更新数据的时候只需要更新主键索引树，
     二是节省存储空间。
 2.为什么推荐InnoDB表必须有主键？
     保证会有主键索引树的存在（因为数据存放在主键索引树上面），如果没有mysql会自己生成一个rowid作为自增的主键主键索引
 3.为什么推荐使用整型的自增主键？
 	一是方便查找比较，
 	二是新增数据的时候只需要在最后加入，不会大规模调整树结构，如果是UUID的话，大小不好比较，新增的时候也极有可能在中间插入数据，会导致树结构大规调整，造成插入数据变慢。

​       三：索引空间大小上可能有优势

4.何时分库分表?

阿里巴巴《Java 开发手册》提出单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表 ;

根据实际内存服务器情况，如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。 

## 分布式

##### 一致性hash

传统求余做[负载均衡](https://so.csdn.net/so/search?q=%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1&spm=1001.2101.3001.7020)算法，缓存节点数由3个变成4个，缓存不命中率为75%。计算方法：穷举hash值为1-12的12个数字分别对3和4取模，然后比较发现只有前3个缓存节点对应结果和之前相同，所以有75%的节点缓存会失效，可能会引起缓存雪崩。 

采用翻倍扩容，避免数据映射全部打乱而全部迁移，翻倍迁移只发生50%的数据迁移 

一致性hash算法 加入和删除节点只影响哈希环中顺时针方向的相邻的节点，对其他节点无影响。 

数据的分布和节点的位置有关，因为这些节点不是均匀的分布在哈希环上的，所以数据在进行存储时达不到均匀分布的效果。所以，出现了增加虚拟节点的方式来减少不均衡的现象。 

![img](https://img-blog.csdnimg.cn/0059405a45674e1899e88826c11139f4.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-r5oiR5ouW6Z6L5ZOl,size_20,color_FFFFFF,t_70,g_se,x_16) 

所以采用红黑树是最稳妥的实现方法。Java中直接使用TreeMap即可。 

--https://blog.csdn.net/gonghaiyu/article/details/108375298

##### 幂等性

指的是多次请求接口后不会造成坏的影响，比如重复消费、表单重复提交。

1. 状态机实现幂等：即关注点是状态是否发生变化，若已经是更新后的状态，那么再收到调用请求也不做更新

2. 数据库唯一约束实现幂等

3. 通过tokenid的方式去识别每次请求判断是否重复

   先请求一个token，提交带上，后端比较token，满足后清空token，并执行业务。（防止并发，可以用redis）

   

   最终一致性方式解决

   TCC两阶段补偿方案

   TCC是Try-Conﬁrm-Cancel， 比如在支付场景中，先冻结一笔资金，再去发起支付。如果支付成功，则将冻结资金进行实际扣除；如果支付失败，则取消资金冻结

   - Try阶段：完成所有业务检查（一致性），预留业务资源（准隔离性）
   - Conﬁrm阶段：确认执行业务操作，不做任何业务检查，只使用Try阶段 预留的业务资源。
   - Cancel阶段：取消Try阶段预留的业务资源。Try阶段出现异常时，取消所有业务资源预留请求



##### 分布式锁 

1、处理效率提升：应用分布式锁，可以减少重复任务的执行，避免资源处理效率的浪费；

2、数据准确性保障：使用分布式锁可以放在数据资源的并发访问，避免数据不一致情况，甚至数据损失等

分布式锁的实现前提：
分布式的**CAP理论**：任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。

通常情况下，大家都会牺牲强一致性来换取系统的高可用性，这样我们很多的场景，其实是只需为了保证数据的“最终一致性”。 

**BASE 理论**

（Basically Available）基本可用
在分布式系统出现故障的时候，允许损失部分可用性，即保证核心可用。

（Soft State）软状态
接受一段时间的状态不同步，及中间状态，而改中间状态不影响系统整体可用性。这里的中间状态就是CAP理论中的数据不一致性。

（Eventually Consistent）最终一致性
上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态
————————————————
原文链接：https://blog.csdn.net/universsky2015/article/details/105727244



分布式锁可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行。

场景比如: job部署在多台服务器，不希望重复执行产生垃圾数据等。分布式锁+幂等（状态机实现幂等）

**分布式锁的实现方式**有：
 数据库实现分布式锁：

1.原理简单，性能较差：创建一个表，插入记录成功的获得执行权（利用主键唯一性），完成后删除。

2. Redis分布式锁：性能最好：【setnx】命令实现分布式锁（set if not exist）
3. Zookeeper分布式锁：可靠性最好



##### 集群或分布式环境下，session的3种处理策略 

通过粘性Session，Session复制或Session共享 

1。粘性Session是指将用户锁定到某一个服务器上 

2。任何一个服务器上的session发生改变（增删改），该节点会把这个 session的所有内容序列化，然后广播给所有其它节点，不管其他服务器需不需要session，以此来保证Session同步。 

3。广泛性而言，第三种方式，也就是基于第三方缓存框架共享session，应用的最为广泛 

## 高并发

秒杀系统设计

解决高并发的方法主要有：系统拆分，缓存，MQ, 还有分库分表，读写分离等也是分而治之的思想。 

RabbitMq的消息队列除了有解耦和异步的功能外，还可以实现流量削峰 



##### 延时队列，死信队列

生产环境中是不太可能使用JDK原生延迟队列DelayQueue 的，它是**没有持久化**的，重启就会导致数据丢失（也可以：宕机重启，执行任务恢复，从数据库扫描添加回延时队列即可 ） 

1.**有赞**的延迟队列就是基于通过Redis 的`zset`进行设计和存储的 

2.`RabbmitMQ`它的延迟队列机制本质上也是通过`TTL`（Time To Live 消息存活的时间）所实现的，当队列里的元素触发了过期时，会被送往到`Dead Letter Exchanges`（死信队列中)。我们可以将死信队列的元素再次转发，对其进行消费，从而达到延迟队列的效果。 

3.`RocketMQ`的延时等级队列机制 

4.用定时任务 再处理消息也可以



##### 分库分表

数据库的高可用。水平垂直拆分，再到主从复制，读写分离

id如何生成？数据库自增ID、Redis中维护offset、snowflake算法（ twitter 开源的分布式 id 生成算法 ）、基于数据库的号段模式 

- 分库分表，首先得知道瓶颈在哪里，然后才能合理地拆分（分库还是分表？水平还是垂直？分几个？）。且不可为了分库分表而拆分。（比如单表数量量太大则水平分表、单表热点字段太多则垂直分表）

- 选key很重要，既要考虑到拆分均匀，也要考虑到非partition key的查询。

- 只要能满足需求，拆分规则越简单越好。

  实施：大公司用 **mycat** 中间件 Proxy 代理模式 （独立部署） ,小公司用 **（**[`ShardingSphere`](https://github.com/apache/incubator-shardingsphere) **）sharding-jdbc** 客户端，引入jar包

数据分发算法：按照某个字段 Hash ，**缺点** ：扩容比较麻烦 ，需要数据迁移



### 网络

cookie和session

post和put:PUT方法是幂等的，POST方法不是幂等 

1. POST /url 创建
2. PUT /url/xxx 更新

## JDK

java8新特性，四大函数式接口，然后默认方法

##### 注解

注解的本质就是一个继承了 Annotation 接口的接口 

虚拟机将采用 JDK 动态代理机制生成一个目标注解的代理类 ，AnnotationInvocationHandler 中 invoke 方法的实现逻辑，这是核心。一句话概括就是，**通过方法名返回注解属性值** 

##### 枚举

枚举本质上是通过普通的类来实现的，只是编译器为我们进行了处理。每个枚举类型都继承自java.lang.Enum，并自动添加了values和valueOf方法。而每个枚举常量是一个静态常量字段，使用内部类实现，该内部类继承了枚举类。所有枚举常量都通过静态代码块来进行初始化，即在类加载期间就初始化。另外通过把clone、readObject、writeObject这三个方法定义为final的，同时实现是抛出相应的异常。这样保证了每个枚举类型及枚举常量都是不可变的。可以利用枚举的这两个特性来实现线程安全的单例。 

枚举类默认继承Enum抽象类，这也是枚举不能继承其他类的原因 

```
 enum Single2 {
    instance;
    public void doSomething(){
      System.out.println("doing from enum....");
    }
}
==>>>>>
final class Single2
extends Enum<Single2> {
    public static final /* enum */ Single2 instance = new Single2("instance", 0);
    private static final /* synthetic */ Single2[] $VALUES;

    public static Single2[] values() {
        return (Single2[])$VALUES.clone();
    }

    public static Single2 valueOf(String name) {
        return Enum.valueOf(Single2.class, name);
    }

    private Single2(String string, int n) {
        super(string, n);
    }

    public void doSomething() {
        System.out.println("doing from enum....");
    }

    static {
        $VALUES = new Single2[]{instance};
    }
}
```



##### 序列化

java原生：**实现 java.io.Serializable 接口**  writeObject 和 readObject 方法 ，反射

通过判断类的 serialVersionUID 来验证版本一致性的，如果不一致反序列化会报错；

当某个字段被申明为 transient 后，默认的序列化机制会忽略这个字段

被申明为 transient 的字段，如果需要序列化，可以添加两个私有方法：writeObject 和readObject

其他：

基于XML的SOAP协议及对应的 WebService 框架 

基于 JSON 的简单文本格式编码的 HTTP REST 接口 、Jackson  FastJson  GSON  

对性能和间接性有比较高要求的场景，那么 Hessian、Protobuf、Thrift、Avro 都可以 

##### ThreadLocal 

![img](https://pic2.zhimg.com/80/v2-1bf6db1fff9abebaf6361fba154216ad_720w.webp) 

每个线程都**单独拥有一份共享变量**，这样就可以做到线程之间对于共享变量的隔离问题。 

1.ThreadLocal线程本地变量作为一个Thread类的**成员字段** ：ThreadLocal.ThreadLocalMap threadLocals

key就是ThreadLocal 对象本身，get时先得到线程得到Map，算entry数组的index

首先了解一下 ThreadLocalMap 的 hash 算法 `int i = key.threadLocalHashCode & (len-1)`

`ThreadLocalMap`中`hash`算法很简单，这里`i`就是当前 key 在散列表中对应的数组下标位置。这里最关键的就是`threadLocalHashCode`值的计算，`ThreadLocal`中有一个属性为`HASH_INCREMENT = 0x61c88647`。这个值很特殊，它是**斐波那契数** 也叫 **黄金分割数**。`hash`增量为 这个数字，带来的好处就是 `hash` **分布非常均匀**。

不同的ThreadLocal对象有不同的threadLocalHashCode 值；

（冲突的解决线性探测法 private static int nextIndex(int i, int len) {    return ((i + 1 < len) ? i + 1 : 0);}）

为什么ThreadLocalMap.threshold是2/3而HashMap.threshold是0.75
理解了ThreadLocalMap的数据结构之后可以看出 threshold 越大，则数据存储就会越拥挤，而 threshold 小一点的话就可以减少元素操作时遍历的数量了，这从threadLocalHashCode的设计上也能看出
———————————————— 
原文链接：https://blog.csdn.net/qq_25215821/article/details/126393476

使用场景：

场景一：在重入方法中替代参数的显式传递 ，例如在Spring的@Transaction事务声明的注解中就使用ThreadLocal保存了当前的Connection对象，避免在本次调用的不同方法中使用不同的Connection对象。 

场景二：全局存储用户信息 ，以尝试使用ThreadLocal替代Session的使用 

避免内存泄露 ，每次使用完之后都remove掉Entry ；原因：ThreadLocal 对象==null后，只是map的key被回收了，value还是强引用。

子线程要获得父线程的变量，可以用**InheritableThreadLocal**  

##### 软弱强虚引用

##### HashMap

https://www.cnblogs.com/qcblog/p/8449624.html

某个key散列地址计算过程实际就是: indexFor(hash(key.hashCode()),length)

再hash（叫做**扰动函数**）的目地：防止低位相同高位不同的hash值冲突;

扰动函数：(h = key.hashCode()) ^ (h >>> 16); 

将h的哈希值右移16位并与自身相异或 相当于 使自己的高16位和低16位 相异或，得到的值**既包含了自己高位的特性又包含了自己低位的特性**，从而增加了之后得到的下标的不确定性，降低了碰撞的概率。 



解决哈希冲突办法 ：

1.开放定址法：我们在遇到哈希冲突时，去寻找一个新的空闲的哈希地址。
线性探测法：h(x)=(Hash(x)+i)mod (Hashtable.length);（i会逐渐递增加1）
平方探测法（二次探测）：前后都找
2.再哈希法：同时构造多个不同的哈希函数，等发生哈希冲突时就使用第二个、第三个……等其他的哈希函数计算地址，
直到不发生冲突为止。虽然不易发生聚集，但是增加了计算时间。
3.链地址法：将所有哈希地址相同的记录都链接在同一链表中。
4.建立公共溢出区：将哈希表分为基本表和溢出表，将发生冲突的都存放在溢出表中。

 问题：如果一个类的hashcode都是1，会怎么样？

map.put 会退化为单链表，因为hashcode全冲突的；如果equals 也相同，则put会覆盖掉



为什么用31计算hash？

合适的质数发生哈希冲突的可能性更低 ，31可以被JVM优化 ， 31 * i = (i << 5) - i ，位运算提高效率。



dk1.8 数组 + 链表 + 红黑树

当一个结点的链表长度大于8时且数组总长度大于64，该节点的链表会转换成红黑树（其他的节点还是链表），提高查询效率,而链表长度小于6时又会退化成链表



##### 分散热点

*LongAdder的基本思路就是分散热点*,将value值分散到到一个Call数组中,不同线程会命中到数组的不同槽中,各个线程只对自己槽中的那个值进行CAS操作 

ConcurrentHashMap



##### volatile

```
由于现代操作系统都是多处理器操作系统，每个处理器都会有自己的缓存，可能存在不同处理器缓存不一致的问题，而且由于操作系统可能存在重排序，导致读取到错误的数据，因此，操作系统提供了一些内存屏障以解决这种问题.
简单来说:
1.在不同CPU执行的不同线程对同一个变量的缓存值不同，为了解决这个问题。
2.用volatile可以解决上面的问题，不同硬件对内存屏障的实现方式不一样。java屏蔽掉这些差异，通过jvm生成内存屏障的指令。
对于读屏障:在指令前插入读屏障，可以让高速缓存中的数据失效，强制从主内存取。
```

Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。

## 线程池

参数：corePoolSize - 线程池核心池的大小。 maximumPoolSize - 线程池的最大线程数。 keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。 unit - keepAliveTime 的时间单位。 workQueue - 用来储存等待执行任务的队列。 threadFactory - 线程工厂。 handler - 拒绝策略。 

用 `Executors` 工具类中提供的方法。因为这些线程池的创建都不够精细化，也非常容易造成OOM风险 ；使用 new ThreadPoolExecutor() 方式创建的线程池是可以通过提供的 set 方法进行动态调整的。有了这个动态调整的方法后，就可以把线程池包装起来，在配合动态调整的页面，动态更新线程池参数，就可以非常方便的调整线程池了 ；

线程监控：常规继承，重写一些方法，记录信息。

**基于JVMTI方式监控**   非入侵代码 

JVMTI(JVM Tool Interface)位于jpda最底层，是Java虚拟机所提供的native编程接口。JVMTI可以提供性能分析、debug、内存管理、线程分析等功能。

基于jvmti提供的接口服务，运用C++代码(win32-add_library)在Agent_OnLoad里开发监控服务，并生成dll文件。开发完成后在 VM vptions 中配置 加入agentpath，这样就可以监控到我们需要的信息内容。

开源的动态可监控线程池框架（**DynamicTp**） ，项目地址：<https://dynamictp.cn/> 

https://www.shuzhiduo.com/A/D854Ay9QdE/  非入侵，配置中心，多平台告警，轻量级（基于 springboot 实现，引入 starter ）

线程池参数动态化 ：https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html

#### 线程异常怎么办？

捕获异常并处理，如何捕获异常？

对于execute：重写afterExecute、自定义线程工厂并让线程setDefaultUncaughtExceptionHandler

对于submit：重写afterExecute(代码也是通过future.get)、future.get ； 因为异常被捕获并通过setException封装到了futuretask 的outcome里，get时会获取outcome

# jvm原理及调优

https://blog.csdn.net/chh9189185531/article/details/106685830/

![img](https://img-blog.csdnimg.cn/20200611120934431.png) 

## java内存结构

 JMM https://www.jianshu.com/p/76959115d486

![img](https://upload-images.jianshu.io/upload_images/10006199-a4108d8fb7810a71.jpeg?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp) 

程序计数器是一块很小的内存空间，它是线程私有的，可以认作为当前线程的行号指示器。

**每个方法被执行的时候都会创建一个栈帧用于存储局部变量表，操作栈，动态链接，方法出口等信息** 

Java虚拟机栈可能出现两种类型的异常：

1. 线程请求的栈深度大于虚拟机允许的栈深度，将抛出StackOverflowError。
2. 虚拟机栈空间可以动态扩展，当动态扩展是无法申请到足够的空间时，抛出OutOfMemory异常。

 方法区 用于存储已被虚拟机加载的类信息、常量、静态变量，如static修饰的变量加载类的时候就被加载到方法区中。 运行时常量池是方法区的一部分，class文件除了有类的字段、接口、方法等描述信息之外，还有常量池用于存放编译期间生成的各种字面量和符号引用。



```
对象在内存中存储的布局分为 ：
1.对象头 markword
2.实例数据
3.对齐填充
```

![img](https://upload-images.jianshu.io/upload_images/10006199-318ad80ccb29abe4.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp) 

对象头结构

一个类的大小计算

## JVM调优

工具步骤 https://blog.csdn.net/weixin_47184173/article/details/114919061

Sun JDK监控和故障处理命令有top 命令  **jps jstat jmap jhat jstack jinfo** 

Arthas 是Alibaba开源的Java诊断工具。安装在系统所在服务器。可以帮助开发人员或者运维人员查找问题，分析性能，bug追踪。 

MAT的强大之处只要在于对堆与对象的底层分析。在发生内存泄漏，或者OOM的时候 

代码中对线程取了别名，因此可以更快的定位问题线程 

常用措施：

目的：减少fullGC带来的STW -》让年轻代去收集释放垃圾对象 

1.分析业务，估算内存（通过日活、日均订单、并发数、请求的数据量、对象的大小），将年轻代的内存调大 

2.**大对象进入老年代** ：大对象占用空间多，直接放入新生代中会扰乱新生代GC，新生代空间不足将会把大量的较小的年轻代对象移入到老年代中，这对GC来说是相当不利的。如果有短命大对象，对GC来说将会是一场灾难，原本存放于老年代的永久对象，被短命大对象塞满，扰乱了分代内存回收的基本思路，因此，在开发过程中，尽可能避免使用短命的大对象。

3. 如果希望对象尽量留在新生代：可以设置这个参数：

-XX：TargetSurvivorRatio（设置 survivor 的使用率为 90%，默认是50%，提高了survivor 区的使用率，当存放的对象超过这个数值，则对象会向老年代压缩）

-XX：MaxTenuringThreshold=31（设置年轻对象晋升到老年代的最大年龄是31，默认是15，设为31是尽可能地将对象留在新生代） 

```
4、吞吐量优先设置
机器配置是 4G 内存 和 32 核 CPU，配置参数如下：
-Xms3800m  -Xmx3800m（堆的初始值和最大值一样） 
-Xmn2g（新生代大小）
-Xss128k（线程栈大小，减少它使剩余的系统内存支持更多的线程） 
-XX：+UseParallelGC（新生代使用并行回收收集器）
 -XX：ParallelGCThreads=20（垃圾回收的线程数）
 -XX：+UseParallelOldGC （老年代使用并行回收收集器）
```



## 垃圾回收

内存结构 算法 时机 类型

可达性分析算法帮我们解决了哪些对象可以回收的问题 

垃圾收集算法则关心怎么回收 

```
Java堆是GC回收的“重点区域”。堆中基本存放着所有对象实例，gc进行回收前，第一件事就是确认哪些对象存活，哪些死去[即不可能再被引用]
为了高效的回收，jvm将堆分为三个区域
1.新生代（Young Generation）NewSize和MaxNewSize分别可以控制年轻代的初始大小和最大的大小
2.老年代（Old Generation）
3.永久代（Permanent Generation）【1.8以后采用元空间，就不在堆中了】

可作为GC Roots的对象有四种
①虚拟机栈(栈桢中的本地变量表)中的引用的对象。
②方法区中的类静态属性引用的对象，一般指被static修饰引用的对象，加载类的时候就加载到内存中。
③方法区中的常量引用的对象,
④本地方法栈中JNI（native方法)引用的对象
要真正宣告对象死亡需经过两个过程。
1.可达性分析后没有发现引用链
2.查看对象是否有finalize方法，如果有重写且在方法内完成自救[比如再建立引用]，还是可以抢救一下，注意这边一个类的finalize只执行一次，这就会出现一样的代码第一次自救成功第二次失败的情况。[如果类重写finalize且还没调用过，会将这个对象放到一个叫做F-Queue的序列里，这边finalize不承诺一定会执行，这么做是因为如果里面死循环的话可能会时F-Queue队列处于等待，严重会导致内存崩溃，这是我们不希望看到的。]
GC是怎么判断对象是被标记的？通过枚举根节点的方式，通过jvm提供的一种oopMap的数据结构
```

![img](https://upload-images.jianshu.io/upload_images/10006199-854e1de91f66764b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp) 

```
1.标记/清除算法【最基础】
2.复制算法
3.标记/整理算法
jvm采用`分代收集算法`对不同区域采用不同的回收算法。
新生代采用复制算法：将内存分为一块Eden空间和From Survivor、To Survivor【保留空间】，三者默认比例为8:1:1，优先使用Eden区，若Eden区满，则将对象复制到第二块内存区上。但是不能保证每次回收都只有不多于10%的对象存货，所以Survivor区不够的话，则会依赖老年代年存进行分配
 GC开始时，对象只会存于Eden和From Survivor区域，To Survivor【保留空间】为空。
GC进行时，Eden区所有存活的对象都被复制到To Survivor区，而From Survivor区中，仍存活的对象会根据它们的年龄值决定去向，年龄值达到年龄阈值(默认15是因为对象头中年龄战4bit，新生代每熬过一次垃圾回收，年龄+1)，则移到老年代，没有达到则复制到To Survivor。
老年代采用标记/清除算法或标记/整理算法
由于老年代存活率高，没有额外空间给他做担保，必须使用这两种算法。
```

G1(garbage first:尽可能多收垃圾，避免full gc)收集器是当前最为前沿的收集器之一(1.7以后才开始有)，同cms一样也是关注降低延迟，是用于替代cms（CMS采用的是"标记-清除"(Mark Sweep)算法，而且是支持并发(Concurrent)的 ）功能更为强大的新型收集器，因为它解决了cms产生空间碎片等一系列缺陷。

 g1通过并发(并行)标记阶段查找老年代存活对象，通过并行复制压缩存活对象【这样可以省出连续空间供大对象使用】。

g1将一组或多组区域中存活对象以增量并行的方式复制到不同区域进行压缩，从而减少堆碎片，目标是尽可能多回收堆空间【垃圾优先】，且尽可能不超出暂停目标以达到低延迟的目的。

 Minor GC、Major GC、FULL GC、mixed gc

stop the world简单来说就是gc的时候，停掉除gc外的java线程。 

新生代什么样的情况会晋升为老年代？

对象优先分配在eden区，eden区满时会触发一次minor GC

> 对象晋升规则
>  1 长期存活的对象进入老年代，对象每熬过一次GC年龄+1(默认年龄阈值15，可配置)。
>  2 对象太大新生代无法容纳则会分配到老年代
>  3 eden区满了，进行minor gc后，eden和一个survivor区仍然存活的对象无法放到(to survivor区)则会通过分配担保机制放到老年代，这种情况一般是minor gc后新生代存活的对象太多。
>  4 动态年龄判定，为了使内存分配更灵活，jvm不一定要求对象年龄达到MaxTenuringThreshold(15)才晋升为老年代，若survior区相同年龄对象总大小大于survior区空间的一半，则大于等于这个年龄的对象将会在minor gc时移到老年代

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy83eUdpYlRNTE1oWFBmZ0s0aWFpYmNpYlJtZ1NOTVA3SVdBRmliaWNKN3k5amZqMlk0S1hxZ1A2M3V6aWNIamRHWlA3dXZrSVo2SUtERkZMeVJpYnNJSHVJQkZRZ2VBLzY0MA?x-oss-process=image/format,png) 

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy83eUdpYlRNTE1oWFBmZ0s0aWFpYmNpYlJtZ1NOTVA3SVdBRmliWmtSZU9PY3FXSVgxdkZ0RkJaeHI4bEE5U0ZqWVlwRzV5Q0Z1cG90bHZnZzVpY2xjRmljdjJqWUEvNjQw?x-oss-process=image/format,png) 

```
-Xms20m -Xmx20m -Xmn10m -XX:SurvivorRatio=8 -XX:+PrintGCDetails
```

## 类加载

过程 自定义类加载器

- 自己编写的类加载器，需要继承ClassLoader类或URLClassLoader，并至少重写其中的findClass(String
  name)方法，若想打破双亲委托机制，需要重写loadClass方法

- ```
  public abstract class ClassLoader {
    //  每个类加载器都有一个父加载器
    private final ClassLoader parent;
    public Class<?> loadClass(String name) throws ClassNotFoundException {
          return loadClass(name, false);
      }
       protected Class<?> loadClass(String name, boolean resolve)
          throws ClassNotFoundException
      {
              // First, check if the class has already been loaded
              Class<?> c = findLoadedClass(name);
             // 如果没有加载过
              if (c == null) {
                  if (parent != null) {
                    //  先委托给父加载器去加载，注意这是个递归调用
                   c = parent.loadClass(name, false);
                  } else {
                   // 如果父加载器为空，查找 Bootstrap 加载器是不是加载过了
                     c = findBootstrapClassOrNull(name);
                  }
                
              // 如果父加载器没加载成功，调用自己的 findClass 去加载
                  if (c == null) {        
                      c = findClass(name);
                  }
              } 
          
              return c;
          }
          
      }
      //ClassLoader 中findClass方式需要被子类覆盖，下面这段代码就是对应代码
        protected Class<?> findClass(String name){
         //1. 根据传入的类名 name，到在特定目录下去寻找类文件，把.class 文件读入内存
            ...
         //2. 调用 defineClass 将字节数组转成 Class 对象
         return defineClass(buf, off, len)；
      }
        // 将字节码数组解析成一个 Class 对象，用 native 方法实现
      protected final Class<?> defineClass(byte[] b, int off, int len){
      
      }
      
  }
  
  ```

  tomcat打破了双亲委派的原则，实际是在应用类加载器中打破了双亲委派，其他类加载器还是遵循双亲委派的 

  - Catalina ClassLoader ⽤于加载服务器内部可⻅类，这些类应⽤程序不能访问；
  - SharedClassLoader ⽤于加载应⽤程序共享类，这些类服务器不会依赖；
  - WebappClassLoader，每个应⽤程序都会有⼀个独⼀⽆⼆的Webapp ClassLoader，他⽤来加载本应⽤程序 /WEB-INF/classes 和 /WEB-INF/lib 下的类。

  ![img](https://img.jbzj.com/file_images/article/202111/20211118110722158.png?2021101811729) 

https://baijiahao.baidu.com/s?id=1675804610811644518&wfr=spider&for=pc

![img](https://pics1.baidu.com/feed/6f061d950a7b020873653dcada5cd9d4562cc8fd.jpeg@f_auto?token=0c68fa898abec150f15a566e5de4a299) 

加载阶段完成之后，虚拟机就会把外部的二进制字节流（不论从何处获取的）按照一定的数据格式存储在运行时数据区中的方法区。然后在内存中实例化一个java.lang.Class对象 

验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求 

准备阶段是类变量分配内存并设置初始值的阶段。这里的类变量指的是被static修饰的变量，而不包括实例变量。类变量被分配到方法区中，而实例变量存放在堆中。 如果变量被static 和 final同时修饰，则准备阶段直接赋值为指定值。 

解析阶段是将常量池中的符号引用转换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法属性、方法句柄、调用点限定符7类符号引用。 

初始化阶段是执行类构造器 < clinit > 方法的过程。

首先说下类构造器 < clinit > 方法和实例构造器 < init > 方法有什么区别。< clinit > 方法是在类加载的初始化阶段执行，是对静态变量、静态代码块进行的初始化。而< init > 方法是new一个对象，即调用类的 constructor方法时才会执行，是对非静态变量进行的初始化。

使用new关键词创建对象时，访问某个类的静态变量或给静态变量赋值时，调用类的静态方法时。反射调用时，会触发类的初始化（如Class.forName()）初始化一个类的时候，如其父类未初始化，则会先触发父类的初始化。虚拟机启动时，会先初始化主类（即包含main方法的类）。另外，也有些场景并不会触发类的初始化：

通过子类调用父类的静态变量，只会触发父类的初始化，而不会触发子类的初始化（因为，对于静态变量，只有直接定义这个变量的类才会初始化）。通过数组来创建对象不会触发此类的初始化。（如定义一个自定义的Person[] 数组，不会触发Person类的初始化）通过调用静态常量（即static final修饰的变量），并不会触发此类的初始化。因为，在编译阶段，就已经把final修饰的变量放到常量池中了，本质上并没有直接引用到定义常量的类，因此不会触发类的初始化。

##  内存泄漏OOM

现象：1.oom、2.有些场景下还会看到频繁执行full GC ，垃圾回收后，内存并没有减少多少 3.性能下降，莫名崩溃，接口调用失败

jconsole：本地启动后查看内存增长情况，点击执行GC后发现内存没有回收

idea连接方式：添加vm配置，然后启动main方法后，启动jconsole用远程连接127.0.0.1:8888,

```
-Djava.rmi.server.hostname=127.0.0.1
-Dcom.sun.management.jmxremote
-Dcom.sun.management.jmxremote.port=8888
-Dcom.sun.management.jmxremote.ssl=false
-Dcom.sun.management.jmxremote.authenticate=false
```

生产问题可以分析dump文件

可以使用MAT分析堆转储dump文件 

思路：查找哪个对象的个数和占有空间再持续上升，特别是还发生过GC以后；查询是否有大量的线程出现

IDEA中内存分析工具—JProfiler插件

场景：

1.静态属性导致内存泄露
2.未关闭的资源
无论什么时候当我们创建一个连接或打开一个流，JVM都会分配内存给这些资源。比如，数据库链接、输入流和session对象。
如果进行处理呢?第一，始终记得在finally中进行资源的关闭;第二，关闭连接的自身代码不能发生异常;第三，Java7以上版本可使用try-with-resources代码方式进行资源关闭。
3.不当的equals方法和hashCode方法实现
4.使用ThreadLocal
第一，使用ThreadLocal提供的remove方法，可对当前线程中的value值进行移除;
第二，不要使用ThreadLocal.set(null) 的方式清除value，它实际上并没有清除值，而是查找与当前线程关联的Map并将键值对分别设置为当前线程和null。
第三，最好将ThreadLocal视为需要在finally块中关闭的资源，以确保即使在发生异常的情况下也始终关闭该资源。
5.finalize()方法,并且重写的方法在执行时需要一些时间。
6.外部类引用内部类;如果内部类不需要访问外部类的成员信息，可以考虑将其转换为静态内部类。

7.大量线程不能结束导致，比如FutureTask，线程池拒绝策略没有抛异常，后边用到FutureTask.get一直阻塞。

再比如，线程池里的任务需要写日志，但是零点的时候服务器日志切割，导致阻塞，导致堆积线程

大量日志时，从Blocked线程堆栈着手分析，查看PrintStream相关代码 

```
  public void println(String x) {
        synchronized (this) {
            print(x);
            newLine();
        }
    }
```

1.日志量过大导致AsyncAppender日志队列被打满，新的日志事件无法入队，进而由ErrorHandler处理日志，同时由于ErrorHandler存在线程安全问题，导致大量日志输出到了Console，而Console在输出日志到PrintStream输出流时，存在synchronized同步代码块，所以在高并发场景下导致线程Block。 

2.Log4j2打印异常日志时，AsyncLoggerConfig会初始化Disruptor RingBuffer日志元素字段，并进一步触发解析、加载异常堆栈类。JVM通过生成字节码的方式优化反射调用性能，但该动态生成的类无法被WebAppClassLoader类加载器加载，因此当大量包含反射调用的异常堆栈被输出到日志时，会频繁地触发类加载，由于类加载过程是synchronized同步加锁的，且每次加载都需要读取文件，速度较慢，从而导致线程Block。 

4种报错：

java heap space, PermGen space ,unable to create new native thread, GC overhead limt exceeded.

##  springboot

#### spring.factories

在 Spring Boot 项目中，怎样将 pom.xml 文件里面添加的依赖中的 bean 注册到 Spring Boot 项目的 Spring 容器中呢？
你可能会首先想到使用 @ComponentScan 注解，遗憾的是 @ComponentScan 注解只能扫描 Spring Boot 
项目包内的 bean 并注册到 Spring 容器中，项目依赖包中的 bean 不会被扫描和注册。此时，我们需要使用 @EnableAutoConfiguration 
注解来注册项目依赖包中的 bean。而 spring.factories 文件，可用来记录项目包外需要注册的 bean 类名。
使用 spring.factories 文件有什么好处呢？假如我们封装了一个插件，该插件提供给其他开发人员使用。我们可以在 spring.factories 
文件中指定需要自动注册到 Spring 容器的 bean 和一些配置信息。使用该插件的开发人员只需少许配置，甚至不进行任何配置也能正常使用。
2.Spring Boot的扩展机制之Spring Factories

#### 自动装配原理

```
自动装配原理：通过3个注解
@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),
		@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })
public @interface SpringBootApplication {

@SpringBootConfiguration 注解标记启动类为配置类
@ComponentScan 注解实现启动时扫描启动类所在的包以及子包下所有标记为bean的类由IOC容器注册为bean
@EnableAutoConfiguration通过 @Import 注解导入 AutoConfigurationImportSelector类，然后通过AutoConfigurationImportSelector 类的 selectImports 方法去读取需要被自动装配的组件依赖下的spring.factories文件配置的组件的类全名，并按照一定的规则过滤掉不符合要求的组件的类全名，将剩余读取到的各个组件的类全名集合返回给IOC容器并将这些组件注册为bean
————————————————
@Import(AutoConfigurationImportSelector.class)

```

#### 事务不回滚的原因

1.该方法非public方法， spring aop中动态代理时有public的检查

2.被try catch住，未抛出异常的情景

3.非事务方法里调用事务方法， 也是没法调用到动态代理对象

4.抛出检查异常的情况，必须抛出runtimeException或error

## 权限框架Shiro



## Spring AOP

https://www.freesion.com/article/2395275593/

关键在于invoke方法里面，对不同mothed的差异化处理

`invoke`方法的关键就在于，**利用责任链模式，递归调用的方法，来完成advice 的织入**。 

![img](https://www.freesion.com/images/727/6fef823024e0d7b815686159e90b6397.JPEG) 

## 微信小程序开发

注册、微信IDE前端开发、后端服务部署（常规方法，阿里云等上部署一个web服务）、服务URL配置到微信管理台里、发布。

## 基本算法

### 五大算法

分治法
动态规划：

0-1背包问题说的是，给定背包容量W，一系列物品{weiht,value}，每个物品只能取一件，计算可以获得的value的最大值。最优解问题，当然是我们DP，最难的一步还是状态转移方程 ；

**状态转移方程**就是取放进去和不放进去两种情况的最大值"m【i】【j】 = max{ m【i-1】【j-w【i】】+v【i】 , m【i-1】【j】}" 

贪心法
回溯法
分支限界法

### 位图：

https://blog.csdn.net/qq_40100414/article/details/118719748

### 位运算：

a*33=a*32+a*1=a*2^5+a*2^0=a<<5+a<<0;

位运算符	解释
lowbit(i) 即i & -i	返回i的最后一位1
n>>k & 1	求n的第k位数字
x | (1 << k)	将x第k位 置为1
x ^ (1 << k)	将x第k位取反
x & (x - 1)	将x最右边的1置为0(去掉最右边的1)
x | (x + 1)	将x最右边的0置为1
x & 1	判断奇偶性 真为奇，假为偶
————————————————

原码：**是最简单的机器数表示法，用最高位表示符号位，其他位存放该数的二进制的绝对值**。 

反码：**正数的反码还是等于原码；负数的反码就是它的原码除符号位外，按位取反**。 

 计算机采用补码：正数的补码等于它的原码；负数的补码等于反码+1 

###  二分搜索：

```
40亿个随机生产的32位整数，求出一个缺失的数：二进制01二分后，从少的一组里找
```

## **实现2个有序数组的排序**

思路：新建一个空数组temp，数组长度表示为t，以及两个变量i, j标记两组数据当前比较值的下标进行对比，将比较小的值存入temp数组中，同时将下标和数值长度自增1。 

```
function sortFun(data1, data2) {
  var temp = [],
    t = 0,
    i = 0,
    j = 0;
  while (i < data1.length && j < data2.length) {
    if (data1[i] < data2[j]) {
      temp[t++] = data1[i++]; //data1[i]添加到temp中并让t和i自增1
    } else {
      temp[t++] = data2[j++]; //data2[j]添加到temp中并让t和j自增1
    }
  }
  while (i < data1.length) { //data1中剩余的数组添加到temp中
    temp[t++] = data1[i++];
  }
  while (j < data2.length) {  //data2中剩余的数组添加到temp中
    temp[t++] = data2[j++];
  }
  return temp; //返回排完序的新数组
}
```



## 设计模式

23种设计模式代码及jdk或其他实际的示例。

![img](https://images2017.cnblogs.com/blog/401339/201709/401339-20170928225241215-295252070.png) 

todo：实际项目里的应用

#### 代理模式：

```
jdk动态代理：
package src.com.liu.proxy.dynamic.jdk;

import java.lang.reflect.InvocationHandler;
import java.lang.reflect.Method;

//代理对象类
public class JDKDynamicProxy implements InvocationHandler
{
    private TestDao testDao;//被代理对象
    JDKDynamicProxy(TestDao dao){
        this.testDao= dao;
    }
    @Override
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
        Enhancement enhancement = new Enhancement();
        enhancement.check();
        enhancement.except();

        //调用被代理对象方法
        Object obj = method.invoke(testDao,args);

        enhancement.log();
        enhancement.monitor();
        return  obj;
    }
}

main(
//创建被代理对象
        TestDao testDao = new TestDaoImpl();
        //创建代理对象，并将被代理对象注入到代理对象中
        JDKDynamicProxy jdkDynamicProxy = new JDKDynamicProxy(testDao);


        //得到一个类加载器
        ClassLoader classLoader = JDKDynamicProxy.class.getClassLoader();
        //得到被代理对象的所有接口
        Class[] clazz = testDao.getClass().getInterfaces();
        //生成代理对象
        TestDao testDaoAdvice = (TestDao) Proxy.newProxyInstance(classLoader,clazz,jdkDynamicProxy);

        //执行方法
        testDaoAdvice.save(); 
 )
```

cglib动态代理
JDK动态代理是通过重写被代理对象实现的接口中的方法来实现，而CGLIB是通过继承被代理对象来实现，和JDK动态代理需要实现指定接口一样，CGLIB也要求代理对象必须要实现MethodInterceptor接口，并重写其唯一的方法intercept。

CGLib采用了非常底层的字节码技术，其原理是通过字节码技术为一个类创建子类，并在子类中采用方法拦截的技术拦截所有父类方法的调用，顺势织入横切逻辑。（利用ASM开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理）

注意：因为CGLIB是通过继承目标类来重写其方法来实现的，故而如果是final和private方法则无法被重写，也就是无法被代理。

代理模式常用在业务系统中开发一些非功能性需求，比如：监控、统计、鉴权、限流、事务、幂等、日志。我们将这些附加功能与业务功能解耦，放到代理类统一处理，让程序员只需要关注业务方面的开发。除此之外，代理模式还可以用在 RPC、缓存等应用场景中。 



Proxy.newProxyInstance 原理：

```
WeakCache 先冲缓存拿Class对象；拿不到则新生成：
byte[] proxyClassFile = ProxyGenerator.generateProxyClass(
    proxyName, interfaces, accessFlags);
try {
    return defineClass0(loader, proxyName,
                        proxyClassFile, 0, proxyClassFile.length);
  ProxyGenerator里面会动态生成文件对象，包括基本方法（hashCode/equals/toString）及遍历接口里的方法，  方法里会调用handle的 invoke    
```

## GIT

#### 一台电脑（终端）可以配置多个 SSH-Key 用于多个 Git 账号。

换个名称，加个config。 

```
1.ssh-keygen -t rsa -C '[邮箱]' -f ~/.ssh/github_id_rsa
ssh-keygen -t rsa -C '[邮箱]' -f ~/.ssh/gitlab_id_rsa
2.新建config并配置： touch config 、vim config，内容如下：
# github
Host github.com
HostName github.com
PreferredAuthentications publickey
IdentityFile ~/.ssh/github_id_rsa
# gitlab
Host gitlab.com
HostName gitlab.com
PreferredAuthentications publickey
IdentityFile ~/.ssh/gitlab_id_rsa
# 如果生成多个 SSH-Key , 则按上面的格式继续往下写
3.前往 ~/.ssh/ 目录下查看生成的文件：cat [xxx]_rsa.pub
4. 在 Github 或其他 Git 服务器新建 SSH Key，输入文本即可。
```

sourcetree：指定忽略文件，设置->高级:

```
*.iws
*.iml
*.ipr
target/
.settings
.project
.classpath
.externalToolBuilders
*.class
*svn/
.idea/
*.jar
.gitignores
~*
```



#### git常用命令

git clone ***

git push origin master



#### idea破解

安装插件重启即可

plugin：IDE Eval Reset

server：https://plugins.zhile.io  

如果搜索不到，则设置 http proxy—>勾上Auto-detect proxy setting,加上地址 http://127.0.0.1:1080 

## Redis

#### 作用

1. 缓存

2. 数据共享分布式，如应用共享session

3. 全局ID

   int类型，incrby，利用原子性

   `incrby userid 1000`

   [分库分表](https://so.csdn.net/so/search?q=%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8&spm=1001.2101.3001.7020)的场景，一次性拿一段

   5、计数器

   int类型，incr方法

   例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库

   计数功能应该是最适合 Redis 的使用场景之一了，因为它高频率读写的特征可以完全发挥 Redis 作为内存数据库的高效。在 Redis 的数据结构中，string、hash和sorted set都提供了incr方法用于原子性的自增操作，下面举例说明一下它们各自的使用场景：

   如果应用需要显示每天的注册用户数，便可以使用string作为计数器，设定一个名为REGISTERED_COUNT_TODAY的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用incr命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。
   每条微博都有点赞数、评论数、转发数和浏览数四条属性，这时用hash进行计数会更好，将该计数器的 key 设为weibo:weibo_id，hash的 field 为like_number、comment_number、forward_number和view_number，在对应操作后通过hincrby使hash 中的 field 自增。
   如果应用有一个发帖排行榜的功能，便选择sorted set吧，将集合的 key 设为POST_RANK。当用户发帖后，使用zincrby将该用户 id 的 score 增长 1。sorted set会重新进行排序，用户所在排行榜的位置也就会得到实时的更新。
   ————————————————
   原文链接：https://blog.csdn.net/m0_67393593/article/details/125241392

   **点赞、签到、打卡**

   假如上面的微博ID是t1001，用户ID是u3001

   用 like:t1001 来维护 t1001 这条微博的所有点赞用户

   点赞了这条微博：sadd like:t1001 u3001
   取消点赞：srem like:t1001 u3001
   是否点赞：sismember like:t1001 u3001
   点赞的所有用户：smembers like:t1001
   点赞数：scard like:t1001

   **好友关系、用户关注**

   通过`set`解决 交集、差集问题

   ```
   举例
   follow 关注 fans 粉丝
   
   相互关注：
   
   sadd 1:follow 2
   sadd 2:fans 1
   sadd 1:fans 2
   sadd 2:follow 1
   我关注的人也关注了他(取交集)：
   sinter 1:follow 2:fans
   
   可能认识的人：
   用户1可能认识的人(差集)：sdiff 2:follow 1:follow
   用户2可能认识的人：sdiff 1:follow 2:follow 
   ```

   **维护商品标签，类似set**

   - sadd tags:i5001 画面清晰细腻；  sadd tags:i5001 真彩清晰显示屏

   - ```
     SMEMBERS somekey  #查看所有元素
     ```

4. 分布式锁：set lock_key locked NX EX 1  ，如果这个操作返回false，说明 key 的添加不成功，也就是当前有人在占用这把锁。而如果返回true，则说明得了锁，便可以继续进行操作，并且在操作后通过del命令释放掉锁。并且即使程序因为某些原因并没有释放锁，由于设置了过期时间，该锁也会在 1 秒后自动释放，不会影响到其他程序的运行。 

   推荐使用 redisson 第三方库实现分布式锁。 

   https://blog.csdn.net/agonie201218/article/details/121423212





1.KEYS pattern 查找所有匹配给定的模式的键,keys * 查看所有缓存的键

2.DEL key1 key2 删除指定的缓存(一个或多个)，get key //读取  set key value // 写入 

3.自增：

+ incr key // 键值加1 + decr key // 键值减1 + incrby key amount // 键值加amount + decrby key amount // 键值减amount + incrbyfloat key amount // 键值加上浮点数amount 

4.二进制位：

setbit key offset value //把指定的bit位设置为value(value只能是0或1) 

getbit key offset //获取指定bit位的二进制的值 



#### 数据类型及场景

https://www.cnblogs.com/xiaolincoding/p/16370783.html

常见的有五种：**String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）**。 

String 是最基本的 key-value 结构，key 是唯一标识，value 是具体的值，value其实不仅是字符串， 也可以是数字（整数或浮点数），value 最多可以容纳的数据长度是 512M。 底层的数据结构实现主要是 int 和 SDS（简单动态字符串， **SDS 不仅可以保存文本数据，还可以保存二进制数据** ）

一般对象用 String + Json 存储 。

Hash（哈希）：存储对象 ，存储一个哈希表 ，uid:1的键值 > HSET uid:1 name Tom age 15

List（列表）：在redis3.2版本之前，它使用的是ziplist和linkedlist编码作为列表键的底层实现，在它之后，就采用了一个叫做quicklist的数据结构来作其底层实现 ；头部尾部都可以插入移除，场景：消息队列、朋友圈点赞列表，评论列表 

Set（集合）：利用差并交集，点赞、关注、推荐等场景

Zset（有序集合）：排行榜



#### 操作命令

E:\>cd E:\dayDayUp\Redis-x64-3.2.100

E:\dayDayUp\Redis-x64-3.2.100>redis-server redis.windows.conf

启动后，执行redis-cli.exe，运行命令行

https://blog.csdn.net/weixin_53041251/article/details/124440396 命令大全

redis-cli  shutdown 

**String**: set name ***  /  get name  / SETNX name 2222 

**Hash**: HSET key field value / 批量设置 HMSET jie:user:1 name jie age 18 sex nan  /HGET key field 

- **HKEYS** key 获取哈希表中所有字段
- **HVALS** key 获取哈希表中所有值
- **HGETALL** key 获取在哈希表中指定 key 的所有字段和值

**List**：LPUSH name a b c【结果是c ->b ->a】  /LPOP name  /RPUSH name j k l  / RPOP name  左右侧加入、移除对象

lrang list_name 0 -1  查看范围，0表示列表第一个元素,-1表示最后一个元素,-2表示倒数第二个元素 

**Set**: sadd user name sex age /SREM key member .. /SCARD key： 返回set中元素的个数。 

SISMEMBER key member：判断一个元素是否存在于set中。 /SMEMBERS：获取set中的所有元素 

SDIFF key1 key2 ... ：求差集,在key1但不在key2的对象 /SUNION key1 key2 ..：求key1和key2的并集 

SINTER key1 key2 ... ：求key1与key2的交集。

**SortedSet** ： ZADD key score member：添加一个或多个元素到sorted set ，如果已经存在则更新其score值 /删除：ZREM student ming / 获取score：ZSCORE student jie /获取排名：ZRANK student jie 

ZDIFF、ZINTER、ZUNION：求差集、交集、并集 

ZRANGE key min max：按照score排序后，获取指定排名范围内的元素 

ZRANGEBYSCORE key min max：按照score排序后，获取指定score范围内的元素 

#### **Java中使用 Spring Data Redis**

spring-boot-starter-data-redis 

提供了一个高度封装的类：**RedisTemplate** 

针对 Jedis 客户端中大量api进行了归类封装,将同一类型操作封装为operation接口 

HashOperations hashOperations = redisTemplate.opsForHash(); 

ListOperations listOperations = redisTemplate.opsForList();  。。。。

https://blog.csdn.net/qq_61935150/article/details/128401890

#### 面试题

1.基本场景都是单线程，4.0后添加了多线程的支持，主要是在大数据的异步删除功能上

2.单线程为什么也快？基本在内存中完成操作，高效的数据结构哈希表、跳表；

单线程避免多线程的竞争、采用I/O多路复用机制（非阻塞）处理大量客户端的socket请求

3.如何实现数据不丢失？数据持久化

AOF日志，文件追加方式，记录所有的操作命令，写后日志（写日志不检查命令正确性，所以放后边），先命令后日志，恢复时需要全量执行一遍；会阻塞线程

RDB快照，将某个时刻的内存数据二进制写入磁盘

4.0后增加了两种方式的混合持久化方式

4.如何实现高可用

A。主从复制

B。哨兵模式：主服务器宕机，哨兵节点检测到后选举为主服务器

C。集群模式：多个主从模式，为了扩展写能力和储存能力，因为AB只能提高读并发。

集群中多master节点，如何存储选取？一致性hash算法。

5.过期策略？内存淘汰策略？

过期删除策略，是删除已过期的 key，而当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。 

过期删除策略：**惰性删除+定期删除** 

惰性删除是访问key时检查是否超期并删除。定期删除是**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。** 

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/redis/%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5/%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5.jpg) 

**在 LRU 算法中（** Least Recently Used 翻译为**最近最少使用** **）**，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。

**在 LFU 算法中**Least Frequently Used 翻译为**最近最不常用的** ，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 **logc 会随时间推移而衰减的**。 

**高并发下缓存和数据库一致性问题：**

想要保证数据库和缓存一致性，**推荐采用「先更新数据库，再删除缓存」方案，删除缓存部分需配合「消息队列」或「订阅变更日志」的方式来做**。 

## 并发编程源码分析

syncronize 底层原理

volitile 底层原理

锁：公平锁和非公平锁实现原理？可重入锁实现原理？共享锁和排他锁的实现原理？

AQS？state机制

线程池

FutureTask、ExecutorCompletionService

线程通信

阻塞队列

工具类：信号量、降锁、栅栏、



### 队列

LinkedBlockingQueue中的锁是分离的，生产者的锁PutLock，消费者的锁takeLock，提高了线程并发执行的效率 ；内部维护的是一个链表结构 ；一般使用指定长度，若设置为无界队列，队列自身占用很大的内存，容易出现OOM 

而ArrayBlockingQueue生产者和消费者使用的是同一把锁；内部维护了一个数组 

相同点：都是通过ReentrantLock及condition通知机制来实现可阻塞式插入和删除元素并满足线程安全的特性； 

默认非公平take，公平队列也可以实现方式：lock = new ReentrantLock(fair);

### 应用场景

1. 报表 批量任务，多线程并行执行
2. 线程池的队列做限流
3. 阻塞队列应用再日志系统，生产者消费者模式

### 并发的三种场景

#### 分工

多线程并发最基本的场景就是分工。分工，就是线程各司其职，完成不同的工作。分工，也是有很多模式的。比如有:

- 生产者-消费者模式，大厨做饭，我们来吃；
- MapReduce模式，把工作拆分成多份，多个线程共同完成后，再组合结果，Java8中的stream与Fork/Join就是这种模式的体现；
- Thread-Per-Message模式，服务端就是这种模式，收到消息给不同的Thread进行处理；
- ... ...

#### 同步

有分工就要有同步，不同工人之间要协作，不同线程也是。一个线程的执行条件往往依赖于另一线程的执行结果。

线程之间最基本的通信机制是管程模式与wait/notify,除此外还有多个工具类，如：

- Future及其衍生的工具类FutureTask/CompletableFuture等，可以完成异步编程；

- CountDownLatch/CyclicBarrier可以实现特定场景的协作；

- Semaphore提供了经典的PV同步原语（p操作和v操作是不可中断的程序段，称为原语。P,V原语中P是荷兰语的Passeren，相当于英文的pass, V是荷兰语的Verhoog,相当于英文中的incremnet。 

  还可以作为限流器使用；

- ReentrantLock与Condtion,对管程同步的扩展；

- ... ...

#### 互斥

不同工人，操作相同的共享资源，就有可能冲突。类似，多线程访问相同的共享变量，就需要做互斥处理。分工与协作强调的是性能，互斥问题强调的是正确，即线程安全问题。Java解决互斥问题提供了很多思路与工具。

- 避免共享，没有共享，没有竞态，就没有伤害，如ThreadLocal；
- 没有改变，如果大家都不做改变，都是只读的，一起也没有错；
- Copy-on-write，你变你的，我变我的，每变一次都生成新的副本，只要不冲突就可以并行；
- CAS，写入前要看一看，有没有物逝人非（变量和自己读取时一样），没有再写入，否则再做一变；
- Lock，最终手段，但也不想做得太绝，够用就行，ReadWriteLock/StampedLock，够用就行；

互斥问题很像数据库，都是一样的。天下的互斥都是一样的。

## jenkins

jenkins+git+maven搭建自动化部署环境 



 

## JavaScript 

闭包

模块化

## AC架构



## 面试题库

##### 1.跳表的数据结构

![img](https://img-blog.csdnimg.cn/20181029211746472.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Bjd2wxMjA2,size_16,color_FFFFFF,t_70) 

**跳表在原有的有序链表上增加了多级索引，通过索引来实现快速查询。跳表不仅能提高搜索性能，同时也可以提高插入和删除操作的性能。** 每一级索引都最多只需要遍历3个结点。

因此，m=3，所以**跳表查找任意数据的时间复杂度为O(logn)**，这个查找的时间复杂度和[二分查找](https://so.csdn.net/so/search?q=%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE&spm=1001.2101.3001.7020)是一样的，但是我们却是基于单链表这种数据结构实现的。

ConcurrentSkipListMap  ConcurrentSkipListSet 

##### 2.lock与syncronized区别，lock的实现，读写锁的实现，锁升级，锁降级

![img](https://pic3.zhimg.com/80/v2-978013a2b71f7670d3036a496fb4b86a_720w.webp) 

1.synchronized是关键字,Lock是接口;
2.synchronized是隐式的加锁,lock是显式的加锁;
3.synchronized可以作用于方法上,lock只能作用于方法块;
4.synchronized底层采用的是objectMonitor,lock采用的AQS;
5.synchronized是阻塞式加锁,lock是非阻塞式加锁支持可中断式加锁,支持超时时间的加锁;
6.synchronized在进行加锁解锁时,只有一个同步队列和一个等待队列, lock有一个同步队列,可以有多个等待队列;
7.synchronized只支持非公平锁,lock支持非公平锁和公平锁;
8.线程通信：synchronized使用了object类的wait和notify进行等待和唤醒, lock使用了condition接口进行等待和唤醒(await和signal);且可以多路等待
9.与synchronized 不同的是，一旦synchronized 块结束，就会自动释放对someObject的占用。 lock却必须调用unlock方法进行手动释放，
为了保证释放的执行，往往会把unlock() 放在finally中进行；

![img](https://img-blog.csdnimg.cn/bef8b582ef52416b9926856f101b6b1e.png) 

锁升级是synchronized关键字在jdk1.6之后做的优化，锁升级的顺序为：

无锁 -> 偏向锁 -> 轻量级锁 -> 重量级锁，且锁升级的顺序是不可逆的。

锁降级是为了保证数据的可见性在添加了写锁后再添加一道读锁 





##### 3.mysql 优化大偏移量的性能 

通过延迟关联降低扫描的页面（数据列）
select * from (select id from t limit 100000, 10) tmp inner join t using(id);
上面的语句通过先扫描出对应的主键，然后再回表查询出对应的列，极大的减少了MySQL对数据页的扫描。

预先计算分页所在范围
前提条件是在某个有索引的数据列上可以通过计算出对应分页的范围值，且只可根据该索引列排序。
 select * from t_log where id > #{pre_max_id} limit 20; 

##### 4.Java终止线程的方式

**最正确**的停止线程的方式是使用 `interrupt`。 但 interrupt仅仅起到**通知**被停止线程的作用。 而对于被停止的线程而言，它拥有完全的**自主权**，它既可以选择立即停止，也可以选择一段时间后停止，也可以选择不停止。

线程安全

当多个线程访问某一个类(对象或方法)时,这个类始终都能表现出正确的行为,那么这个类(对象或方法)就是线程安全的. 

如何实现序列化

- 序列化机制（包括序列化和反序列化）的本质是用流将对象读到内存和写入外存。

- 实现序列化需要实现Serializable ObjectOutputStream . writeObject / ObjectInputStream .readObject 

- 过运行时判断类的序列化ID（serialVersionUID）来判定版本的一致性 

- 

  Java 常用的序列化方案：

  - hessian
  - kryo
  - json
  - xml

##### 死锁

**产生死锁的四个必要条件**
1、 互斥条件：
进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。

2、不可剥夺条件:
进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放)。

3、 请求与保持条件：
进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。

4、循环等待条件:
存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被 链中下一个进程所请求。即存在一个处于等待状态的进程集合{Pl, P2, …, pn}，其中Pi等 待的资源被P(i+1)占有（i=0, 1, …, n-1)，Pn等待的资源被P0占有，如图2-15所示。 

**6.2 避免死锁**

 加锁顺序：线程按照一定的顺序加锁。 

加锁时限：线程尝试获取锁的时候加上一定的时限，超过时限则放弃对该锁的请求，并释放自己占有的锁。 

## 英文自我介绍 项目介绍

早上好，很高兴能得到这次面试机会。

我将用几分钟时间介绍我自己，让你全面了解我的能力，我的观点，我的项目经历。

我一直从事软件开发相关工作，将近15年；我了解整个软件开发的全过程，需求分析、系统设计、数据库设计、编码、测试、运维等。我有丰富的项目经历，做过10多个大小项目，大部分是web开发、也有app开发。

在大部分项目里，我都是项目骨干，开发骨干、项目组长并成功交付项目。能做到这样，我认为最关键的一点就是设计，可以是系统设计，也可以是一个功能的设计，我总是保证设计先行。做好了设计，后面无论用什么编程语言实现都可以，我所做的项目里也有各种编程语言，有java、javascript、ios object-c、vb.net，这很好的证明了我的观点。

能做好设计，关键的能力是逻辑能力，全面的考虑问题；我认为我擅长做逻辑思考，然后给出完整的解决方案。因此我可以做需求、做设计、做编码、甚至测试。

最后个人兴趣方面，我喜欢的运动是篮球，基本保持一周两次的节奏。适量的运动有助于身心健康，而健康是一切幸福的基础。

我将持续运动下去，也希望结识新的球友。

谢谢，再次感谢给与这个机会



Good morning. my name is allen， I'm glad to have this interview.

I'll take a few minutes to introduce myself.

since I graduated from Dalian Maritime [ˈmærɪtaɪm]  University ,I have worked in the software industry for nearly 15 years. I have rich experience [ɪkˈspɪriəns]  in the whole process of software development, including requirements analysis[əˈnæləsɪs] , system design, database design, coding and testing..

In most projects, I am the *key member* or the team leader and delivered the project successfully; In all development activities ，I think the most *important*  is the design . I always guarantee that the design is finished before the programming. After designed, no matter what programming language you can implement it ； there are diffierent programming languages used in my past projects, such as java, javascript, IOS object-c, vb.net, which is a good proof of my point of view.

The key ability to make a good design is the logical ability  ; I think I'm good at logical thinking  and always *propose*    a complete solution. 

At last,about My hobbies ，my favorite sport is basketball,  basically twice a week. *The exercise* [ˈeksərsaɪz] * is helpful to*   health, and release pressure to maintain a balance between work and life.

That‘s all, thank you again for this opportunity.

During holidays, I usually play basketball with my colleagues or climb mountains  with my family.

I'm sorry. I can't follow you. could you please say slowly?



I completed a Bachelor's Degree in  *Information Management and Information System* ;



##### 中文自我介绍，体现架构能力：

上午好，我叫吴海东，很高兴能得到这次面试机会。我是08年毕业于大连海事大学，

一直从事软件开发相关工作，将近15年；总共去过两家公司，毕业后进入华信，主要做java web项目，比如公积金 社保 人事 教务系统这些，06年加入埃森哲做华为项目，各种类型都有，做过在华为自研框架上做的智能运维业务、穿戴设备相关的IOS app。

大小项目总共做过10多个，所以从需求分析、系统设计、数据库设计、编码各个阶段都有不少项目经验。

近几年的项目，也会同时承担项目管理的角色，管理10人内的小组。但同时技术部分也在做，主要在设计以及一些难度功能的编码实现。

比如运动健康这个项目，最近做的时间比较长的一个项目，做了两年；我要保障每期迭代需求的交付，除了项目管理上任务分配、进度跟踪外，我最重要的工作是做好架构设计、甚至详细设计。一些重点功能我也会做编码实现。这种运作模式非常成功，两年来基本没有出过问题。

今天我应聘的架构师这个职位，我对架构师的理解是这样的，

“软件架构不仅仅是选用什么框架、技术组件，还贯穿了对人的组织、对技术的组织、对业务的组织，来解决业务问题。是一个对技术、管理、业务 综合能力都有要求的职位。在我近15年的工作经历，对这几个方面都有很好的锻炼。我也比较自信能做好这个工作。

最后个人兴趣方面，我喜欢的运动是篮球，基本保持一周两次的节奏。适量的运动有助于身心健康，释放压力，我也会保持这个习惯。

谢谢，再次感谢给与这个机会。

架构师的能力要求：

编程能力：算法、数据结构、os原理、逻辑思维。

架构能力：解决代码规模问题，mvc、设计模式、面向对象等。解决架构

工程能力：团队协作、团队管理、整合一批人完成目标，前后端分离、模块化、质量保证、代码风格”。



Today, I applly for the position of architect [ˈɑːrkɪtekt] . My understanding of architect is as follows:,

"Software architecture is not only about what framework and technology components to choose, but also through the organization of people, technology and business to solve business problems. It need  comprehensive [ˌkɑːmprɪˈhensɪv]  capabilities   with  technology skill, management skill and business skill. In my nearly 15 years of work experience, I have good training in these aspects. I am confident that I can do this job well.

Capability requirements of architects:

Programming ability: algorithm, data structure, os principle, logical thinking.

Architecture ability: solve the problem of code size, mvc, design pattern, object-oriented, etc. Solution architecture

Engineering ability: team cooperation, team management, integration of a group of people to complete the goal, front and rear separation, modularization, quality assurance, code style "

一个项目经历：

我要介绍的项目，它是一个医疗企业针对新产品引入中国市场的过程管理系统，（**New Product Launch ）叫NPL；这个过程是一个长达数年、经历十多项目任务、多团队协作的一个过程， NPL项目以任务管理的方式，将新产品拿证前各团队任务进行系统化记录、追踪，使得新产品上市流程透明化，加强团队间协同，统一管理各类注册用文件，加速新产品上市流程

系统采用微服务架构 Spring Cloud 

我作为唯一后端开发，工作内部包括业务设计、系统设计、DB设计及编码实现；我开发了所有后端工作，前端由另一个同时完成。

这是一个小项目，但是所有的软件开发过程都需要我一个人完成。这很锻炼人。

The project I want to introduce is the process management system of a medical enterprise for the introduction of new products into the Chinese market,  we called NPL ,  short for "New Product Launch"; 

the process of New Product Launch mabe take seveval years,and includes more than ten subtasks,

NPL system can manage the tasks, record  and track the process ,also reminds the task owner to finish it;  there is a dashbord,The department manager can see the overall situation of the new product launch in the next few years

The system uses Spring Cloud  micro-service architecture, database is sqlserver.

I am the only backend developer ,so my job include business design, system design, Database design ,coding and testing.

Although  This is a small project,  all software development processes must be completed  by myself. This is really a challenge for me.  Finally, the project was successfully completed.

 knowledge transfer*(KT)* 



项目2：

The project I want to introduce is “Huawei Sports Health ios app”；

as you know，Huawei sells  various [ˈveriəs]  smart watches and smart bands, and a large number of users use the iPhone ;so the Sports Health app for iPhone user is  becoming more and more important。

The app can connect smart devices, sync data, setting configurations, and graphically display various health data and other basic functions;

In addition, the app also support users to do various [ˈveriəs]  sports such as walking\running \ cycling , and record sport data .

The project ran by agile development, two months each iteration.

I am responsible for a team of about 10 numbers, In addition to management, I also do system design and finished some difficult functions。

The project lasted for about two years and My team basically ensured the successful delivery of each iteration and be considered as the best team.

(Blood oxygen [ˈɑːksɪdʒən] 、blood pressure [ˈpreʃər] 、sleep、heart rate、weight ，body fat、sport data)

## 公司准备

#### topnext

熟悉设计模式，熟悉并发编程，有分布式系统开发经验。 



#### 中恩泰奥  乐天

面试基本就是简历里的内容；

先自我介绍，以及说一下自己的优势；擅长什么，熟悉什么，哪些技术比较深入；

至少能在工作中交流技术问题。 

面试肯定会围绕做过的项目 技术进行讨论；

也会了解人选长期发展，稳定性；职业规划；以及想进乐天的原因以及薪资这些问题。



1面hr 英语，2面技术，3面德国架构师 英文

1.自我介绍、项目介绍

2.为什么离开上家公司？

there were not too many projects 

 because of the last job that requires me to take a business trip for a whole year，and because of my familiy resean，i can‘nt  take a long trip。so i decided to look for anther job of  no business trip。

3.为什么来我公司？

Deliver Digital Transformation，Life Science Data Platform，scientific data  

数据存储、管理、展示

what are your strengthes?



what are your weaknesses?

where do you see yourself in five years?

in five years,I'd like to be seen as someone with deep expertise in software development.

do you work under the pressure?

there were many tight deadlines and stressful situations at my previous jobs.

I've always delivered high quality work and respected my deadlines.



sounds good,I look forward to it.

### 「Veeva」维我软件

Veeva是一家美国基于SaaS模式的医疗CRM系统提供商
生命科学 Life Sciences ：**2024年生命科学市场规模达到约800亿元的市场规模** 

*SaaS*（Software as a Service) :

系统集成

*CRM*（Customer Relationship Management） 的价值在于突出销售管理、营销管理、客户服务与支持方面的重要性 

简历体现：

2.5w

为什么来我们公司？

过去的经历主要是项目型，各种行业项目都有所接触，但都没有深入的积累与沉淀；

后面的职位规划上，更着重某一行业的积累。

维我软件专注于生命科学领域的解决方案，中国老龄化越来越严重，生命科学领域是未来具有潜力的领域，大有作为。

问题：

大连分公司的业务在现在及未来的定位或分工或地位是什么样？

对出差有没有要求？

薪酬福利的架构简单介绍一下？

微信开发



### 腾讯无线：

- jvm命令参数，调优经验。 5，一定要懂一些框架原理。 
- spring的核心源码，生命周期，代理的实现细节。设计模式的掌握了解

比如redis的基本类型，一般人都会答，但是他的底层如何，为啥redis作者会这么做，感觉面试难度还是有的。 

**整数数组和压缩列表在查找时间复杂度方面并没有很大的优势，那为什么 Redis 还会把它们作为底层数据结构呢？**

答：

五种数据形式的底层实现             a，string：简单动态字符串             b，list：双向链表，压缩列表             c，hash：压缩列表，哈希表             d，Sorted Set：压缩列表，跳表             e，set：哈希表，整数数组 

1、内存利用率，数组和压缩列表都是非常紧凑的数据结构，它比链表占用的内存要更少。Redis是内存数据库，大量数据存到内存中，此时需要做尽可能的优化，提高内存的利用率。
2、数组对CPU高速缓存支持更友好，所以Redis在设计时，集合数据元素较少情况下，默认采用内存紧凑排列的方式存储，同时利用CPU高速缓存不会降低访问速度。当数据元素超过设定阈值后，避免查询时间复杂度太高，转为哈希和跳表数据结构存储，保证查询效率。

### 安永

1、8年以上Java开发经验，3年以上架构经验； 2、具有扎实的Java基础知识，对多线程，IO，集合等有深入的了解，熟悉JVM原理，有JVM调优和问题排查经验； 3、熟悉主流Java Web框架，包括SpringCloud，SpringBoot，Spring MVC,，Mybatis等，掌握其原理和机制； 4、熟悉分布式系统的设计和开发，熟悉数据库，缓存，消息队列，负载均衡，任务调度等技术； 5、熟悉阿里云、Azure云、腾讯云、华为云（一种以上）； 6、英语可以流利沟通。 

任务调度

**ScheduledExecutorService** 

Quartz框架 

springmvc：

![img](https://img-blog.csdnimg.cn/20210706101253315.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NzE1MDIxNQ==,size_16,color_FFFFFF,t_70) 

mybatis

**原理详解：**

MyBatis应用程序根据XML配置文件创建SqlSessionFactory，SqlSessionFactory在根据配置，配置来源于两个地方，一处是配置文件，一处是Java代码的注解，获取一个SqlSession。SqlSession包含了执行sql所需要的所有方法，可以通过SqlSession实例直接运行映射的sql语句，完成对数据的增删改查和事务提交等，用完之后关闭SqlSession。

缺点：1.编写SQL语句时工作量很大，尤其是字段多、关联表多时，更是如此。

2、SQL语句依赖于数据库，导致数据库移植性差，不能更换数据库

Mybatis-plus:  ：基本curd不用写sql、分页插件。

**特点：**

- 无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑
- 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作
- **强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求**
- 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错
- 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题
- 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作
- 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ）
- 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用
- **内置分页插件**：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询
- 分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer 等多种数据库
- 内置性能分析插件：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询
- 内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作

**JVM调优和问题排查经验**

1.redis 设置失效时间时，最好错开时间（加个随机值），避免集中缓存失效查库引发性能问题

2.GC：目前在小内存应用上 CMS 的表现大概率仍然要会优于 G1，而在大内存应用上 G1 则大多能发挥其优势，这个优劣势的 Java 堆容量平衡点通常在 6GB 至 8GB 之间 

3.**为什么发生 mixed GC ？**

当达到 IHOP 阈值，`-XX:InitiatingHeapOccupancyPercent`（默认45%）时，老年代使用内存占到堆总大小的 45% 的时候，G1 将开始并发标记阶段 + Mixed GC。

最终标记阶段 - Remark ref-proc 其实是对各种软弱虚引用等的处理。 

在 MySql jdbc 驱动代码中发现，NonRegisteringDriver 类有个虚引用集合 connectionPhantomRefs 用于存储所有的数据库连接， 



根据这么多年性能压测积累的经验，归纳提炼了以下几点排查调优思路： CPU过高，怎么排查问题 linux内存 磁盘IO 网络IO java 应用内存泄漏和频繁 GC java 线程问题排查 常用 jvm 启动参数调优 



从方向、业务、构建方面的架构工作

从业务构建、人员构建、技术框架构建三方面进行。

审计、税务项目经验

应聘该职位的原因？

目前公司的工作由于项目需要长期出差，由于家庭原因不太适合长期出差；

猎头给我推荐了安永这个职位，我知道安永是4大会计师事务所 ，我还真不知道安永也有it类的职位。

这次也是个很好的机会，能接触到全新的业务行业。

##### 架构师

软件架构不仅仅是选用什么框架、技术组件，还贯穿了对人的组织、对技术的组织、对业务的组织，来解决业务问题。

组织业务：同探索和研究业务领域的知识，构建自身看待业务的“世界观”，并拆分业务生命周期、确定业务边界，构建出一套解决特定业务问题的领域模型，进一步完成领域内要素的组织共工作。

架构师的能力要求：

编程能力：算法、数据结构、os原理

架构能力：解决代码规模问题，mvc、设计模式、面向对象等

工程能力：团队协作、团队管理、整合一批人完成目标，前后端分离、模块化、质量保证、代码风格



todo: 把场景加入项目

1. oom ：

2. 消息队列 ：日志打印（异步）、邮件发送 （业务解耦）、流量消峰：消息攒在队列里，消费端慢慢消费，应对突发流量。

      rocketmq ：一个微服务用一个topic，不同业务用tag区分。

3. redis：数据缓存，项目数据字典、一些配置等做缓存。

4. 分布式锁:  集群部署 定时任务重复问题

## 工作中遇到的问题

1. 难题，如何解决

   最近一个项目，因为有个excel导入的需求，里面有7个sheet页面，每个字段都有几十个，导入的字段需要做各种校验，长度、必填，数据类型、日期校验、字典校验，校验不符合还得输出错误提示“哪个字段什么不符合”，工期只有1个星期，如果按照以往每个字段单独写一个方法去做校验，时间不太够，调试也不方便；

   不写死代码就必须循环自动化方式去处理，首先需要配置这些信息，哪个字段需要做什么校验；

   因为excel导入有个对应的model，上面已经配置了不少信息，如中文名，是否必填，所有我就想到用注解，开发一个注解，然后字段上配置上需要的信息。excel导入后，先解析出model上的注解信息，循环对每个校验即可。这个方案是个通用方案，所有java的excel导入可以直接拿去用。

   ios btproxy需求的开发：难点在于技术领域不熟悉，包括tcp udpsocket的调用，定制的蓝牙报文协议与蓝牙表做数据交互，报文的分包合并，这过程的问题调试。

2. oom

   开发中遇到,比如  递归调用时发生过栈内存溢出

   -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/temp/dump 

   线程池带future任务，自定义拒绝策略没有抛出异常导致。

3. 设计模式

   策略模式:  推荐算法实现时，每个条件维度都是一个算法类，然后组合所有选定的算法，依次传入内容类调用处理

   单例： 公积金后台的数据发送接受解析器，就是一个单例。

   模板方法:

   责任链:  hr系统，人员的初始工资导入时，工资的各种校验，比如岗位工资，会根据你的级别，你的职务、工龄，男女不一样算法不一样。

   每种校验一个类，所有的校验配置起来，依次校验接口。而且这种校验后期会随政策不断增加或淘汰

4. 你的缺点

   1.不会营销自己，其实公司里也像个小社会，我在各个不同的项目都能得到同时 经理的认可，但是项目以外并没有什么影响力，以后多加强这方面的活动，比如跨部门的一些会议、技术交流、技术培训等等。

   2.在工作中我要求自己、也要求团队，任何事情要及时闭环。形成了习惯。

   以至于在家里，也要求家人这样，比如饭后不及时清洗而是先刷一会手机、孩子做完手工也不及时收拾而是干另一件事情去了。。等等情况，经常被老婆吐槽，工作跟家庭分不清，家里应该要轻松一些，随意一点。

   我也慢慢说服自己，想了一个理由，借鉴分布式系统的一个理论，“最终一致性”，这个只要“最终闭环”也行吧。

   

5. 你的优点

   我做的项目大小有十几个了，从中我提取出我的核心优点：

   考虑问题比较全面，比如评估工作量、做开发计划，综合考虑各种风险情况、人员情况、各种约束以及现状，综合所有因素做出一个计划或方案。

   还有一个就是做项目的时候坚持做设计，这是我这么多年来做项目总结的最重要的一个步骤。即使有的项目并不要求。设计统一了需求方、开发人员、测试人员多方的意见，减少后期的理解误差与沟通成本。设计可以提前识别问题与风险。 

   

6. 其他观点

   对敏捷的思考：整个项目走敏捷管理，每个迭代里我建议按瀑布模式开发。瀑布的优点是比较稳，一步一步走。比如需求设计编码测试。我们要保证每个步骤都要有，尤其是设计，往往很多敏捷项目团队被忽略。

   设计统一了需求方、开发人员、测试人员多方的意见，减少后期的理解误差与沟通成本。设计可以提前识别问题与风险。当然设计也可以按敏捷的模式运作，比如设计的形式、文档可以轻量级，设计可以与编码等其他阶段并行，设计一部分开发一部分，避免等待浪费工作量

7. 过去项目中哪个觉得可以有改进的地方



## IDEA快捷键

ctrl+r  替换
ctrl+f  当前查找
ctrl+shift+f 全局查找 也可 double shift
ctrl+alt + 左箭头   回退
ctrl+alt + O   去除无用包
alt + enter   引入某包
ctrl+alt + H   查看调用关系
ctrl+G 行号