# 学习总结

## 微服务

1、服务发现——Netflix Eurek

该系统下还分为Eureka服务端和Eureka客户端，Eureka服务端用作服务注册中心，支持集群部署。Eureka客户端是一个java客户端，用来处理服务注册与发现

2、客服端负载均衡——Netflix Ribbon

基于Http和Tcp的客户端负载均衡，使得面向REST请求时变换为客户端的负载服务调用，提供客户端的软件负载均衡算法。

3、断路器——Netflix Hystrix

它的作用是保护系统，控制故障范围。

1. 服务降级(fallback)

服务器忙，请稍后再试，不让客户端等待并立刻返回一个友好提示，fallback

哪些情况会出发降级

程序运行导常
超时
服务熔断触发服务降级
线程池/信号量打满也会导致服务降级
2. 服务熔断(break)

类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示。

服务的降级 -> 进而熔断 -> 恢复调用链路

3. 服务限流(flowlimit)

秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟N个，有序进行。


4、服务网关——**Spring Cloud Gateway** 

提供api网关，路由，负载均衡等作用；API 网关是一个搭建在客户端和微服务之间的服务，我们可以在 API 网关中处理一些非业务功能的逻辑，例如权限验证、监控、缓存、请求路由等 

网关最基本的模块。它由一个 ID、一个目标 URI、一组断言（Predicate）和一组过滤器（Filter）组成。 

```
filter里数据量大偶发乱码问题解决：
public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {
 DataBufferFactory bufferFactory = originalResponse.bufferFactory();
        ServerHttpResponseDecorator decoratedResponse = new ServerHttpResponseDecorator(originalResponse) {
            @Override
            public Mono<Void> writeWith(Publisher<? extends DataBuffer> body) {
             if (body instanceof Flux) {
                    Flux<? extends DataBuffer> fluxBody = (Flux<? extends DataBuffer>) body;
                    return super.writeWith(fluxBody.buffer().map(dataBuffers -> {//解决返回体分段传输
                    
                    //如果响应过大，会进行截断，出现乱码，然后看api DefaultDataBufferFactory有个join方法可以合并所有的流，乱码的问题解决
                        DataBufferFactory dataBufferFactory = new DefaultDataBufferFactory();
                        DataBuffer join = dataBufferFactory.join(dataBuffers);
                        byte[] content = new byte[join.readableByteCount()];
                        join.read(content);
                        //释放掉内存
                        DataBufferUtils.release(join);
                        //组装apiLog对象，用于记录api请求日志
                        String result = new String(content, StandardCharsets.UTF_8);
                        //---end
```

5、分布式配置——Spring Cloud Config

提供服务端和客户端，服务器存储后端的默认实现使用git

Spring Cloud Feign 是一个声明web服务客户端，这使得编写Web服务客户端更容易，使用Feign 创建一个接口并对它进行注解 

Zipkin是一个分布式跟踪系统。它有助于收集解决服务架构中延迟问题所需的计时数据。特性包括此数据的收集和查找。 

 Spring Cloud Sleuth：分布式跟踪实现， 可以完美整合Zipkin。  

**Spring Cloud Security** 



**ES=elaticsearch** **分布式全文检索引擎** 

## MQ

[消息队列](https://so.csdn.net/so/search?q=%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97&spm=1001.2101.3001.7020)中间件是分布式系统中重要的组件，主要解决异步消息，应用解耦，流量削锋和消息通讯四个场景等问题，实现高性能，高可用，可伸缩和最终一致性架构。目前使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ 

1.异步消息：用户注册后，异步发注册邮件和注册短信 

2.应用解耦：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口 ；假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，订单系统与库存系统耦合 

订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功 库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作 

3.流量削锋：秒杀或团抢活动中 ，用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。

4.日志处理是指将消息队列用在日志处理中，比如[Kafka](https://so.csdn.net/so/search?q=Kafka&spm=1001.2101.3001.7020)的应用，解决大量日志传输的问题。架构简化如下 

##### 如何保证消息不丢失

RocketMQ
一、Producer保证消息不丢失

1、RocketMQ发送消息有三种模式，即同步发送，异步发送、单向发送。

同步发送消息时会同步阻塞等待Broker返回发送结果，如果发送失败不会收到发送结果SendResult,这种是最可靠的发送方式。
异步发送消息可以在回调方法中得知发送结果。
单向发送是消息发送完之后就不管了，不管发送成功没成功，是最不可靠的一种方式 

生产者的重试机制 

mq为生产者提供了失败重试机制，同步发送和异步发送默认都是失败重试两次当然可以修改重试次数，如果多次还是失败，那么可以采取记录这条信息，然后人工采取补偿机制。 

**二、Broker保证消息不丢失**

1、刷盘策略

RocketMq持久化消息有两种策略即同步刷盘和异步刷盘。默认情况下是异步刷盘，此模式下当生产者把消息发送到broker，消息存到内存之后就认为消息发送成功了，就会返回给生产者消息发送成功的结果。但是如果消息还没持久化到硬盘，服务器宕机了，那么消息就会丢失。同步刷盘是当Broker接收到消息并且持久化到硬盘之后才会返回消息发送成功的结果，这样就会保证消息不会丢失，但是同步刷盘相对于异步刷盘来说效率上有所降低，大概降低10% 

集群模式

rocketmq的集群模式保证可rocketMQ高可用。利用多master多slave节点保证rocketmq的高可用；此模式是broker保证消息不丢失的配置，主从复制同步复制，刷盘模式同步刷盘，但是这种模式下性能会有所降低 

三、**Consumer保证消息不丢失** 

1、手动ack    业务成功后才返回状态 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS 

## redis

##### 穿透 击穿 雪崩

1、缓存穿透
缓存穿透：指在redis缓存中不存在数据，这个时候只能去访问持久层数据库，当用户很多时，缓存都没有命中就会照成很大压力
解决方案 ：
（1）布隆过滤器（对可能查询的数据先用hash存储）
（2）缓存空对象：在没有的数据中存一个空，而这些空的对象会设置一个有效期）

2、缓存击穿
缓存击穿：指在同一个时间内访问一个请求的请求数过多，而在这个时候缓存某个key失效了，这个时候就会冲向数据库照成缓存击穿
解决方案：
（1）设置缓存永远不过期
（2）加互斥锁，使用分布式锁，保证每个key只有一个线程去查询后端服务，而其他线程为等待状态。这种模式将压力转到了分布式锁上

3、缓存雪崩
缓存雪崩：在某个时间段，缓存集体过期、redis宕机、增加删除节点导致
解决方案：给key的失效时间设置为随机时间，避免集体过期；双缓存；加互斥锁

原文链接：https://blog.csdn.net/weixin_44975592/article/details/126287594

## Mysql

##### B+树

![img](https://img-blog.csdnimg.cn/img_convert/398aa23eb83e3170d7a41da31b2c8ddd.png) 

1、B+树的所有数据都存储在叶子节点，非叶子节点只存储索引。

2、叶子节点中的数据使用双向链表的方式进行关联。

2、原因分析
我认为，MySQL索引结构采用B+树，有以下4个原因：

1、从磁盘I/O效率方面来看：B+树的非叶子节点不存储数据，所以树的每一层就能够存储更多的索引数量，也就是说，B+树在层高相同的情况下，比B树的存储数据量更多，间接会减少磁盘I/O的次数。

2、从范围查询效率方面来看：在MySQL中，范围查询是一个比较常用的操作，而B+树的所有存储在叶子节点的数据使用了双向链表来关联，所以B+树在查询的时候只需查两个节点进行遍历就行，而B树需要获取所有节点，因此，B+树在范围查询上效率更高。

3、从全表扫描方面来看：因为，B+树的叶子节点存储所有数据，所以B+树的全局扫描能力更强一些，因为它只需要扫描叶子节点。而B树需要遍历整个树。

4、从自增ID方面来看：基于B+树的这样一种数据结构，如果采用自增的整型数据作为主键，还能更好的避免增加数据的时候，带来叶子节点分裂导致的大量运算的问题。
————————————————
原文链接：https://blog.csdn.net/gupaoedu_tom/article/details/125018395

##### 联合索引的底层结构

**必须有第一个索引字段存在才走索引，可以=也可以范围。**

![在这里插入图片描述](https://img-blog.csdnimg.cn/5f5abd674df046edad4832eab77679a2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAbGl1X3NoaV9qdW4=,size_20,color_FFFFFF,t_70,g_se,x_16) 

索引长度计算方法
计算规则
1.索引字段，没有设置NOT NULL，需要占用一个字节。NULL在mysql中是用一个标志位来表示的，用一个字节,null也走索引，并且排在索引的最前面。并不是有些说法说的那样不走索引的
2.定长字段：tinyiny占1个字节、int占4个字节、bitint占8个字节、date占3个字节、datetime占5个字节，char(n)占n个字符。
3.变长字段：varchar(n)占n个字符+2个字节。
4.不同的字符集，一个字符占用的字节数不同：

latin1编码，每个字符占用一个字节
gbk编码，每个字符占用两个字节
utf8编码，每个字符占用三个字节
utf8mb4编码，每个字符占用四个字节

explain select  * from city where  population = 731200  and name = '3' and district = '12'

像上面的例子，我用的是utf8编码，并且没有设置不可为null。
name索引长度： 2553+2+1=768 （null标志位占一个字节）
age索引长度：4+1=5 （null标志位占一个字节）
position索引长度： 2553+2+1=768 （null标志位占一个字节）
————————————————
原文链接：https://blog.csdn.net/liu_shi_jun/article/details/123132731

不走索引：列做了显性或隐性的类型转换、使用函数、使用'%**'开头、没有使用第一个列、使用了！=或is not null 、范围查询会导致其后边的列不走索引、某列没出现会导致它及以后的都不走索引

**在MySQL中，支持两种排序方式，分别是FileSort和Index排序。**

- Index排序中，索引可以保证数据的有序性，不需要再进行排序，效率更好。

- FileSort排序则一般在内存中进行排序，占用CPU较多。如果待排结果较大，会产生临时文件IO到磁盘进行排序的情况，效率较低。

  order by 不走索引问题：1.强制索引 FORCE INDEX（key） 2.联合索引

##### 回表的含义

**根据非主键索引查询到的结果并没有查找的字段值，此时就需要再次根据主键从聚簇索引（主键索引）的根节点开始查找，这样再次查找到的记录才是完成的。** 

如果查询结果中只是索引的字段，则不需要回表。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200616160842582.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ptZW1vcnlz,size_16,color_FFFFFF,t_70) 



 为什么非主键索引结构叶子节点存储的是主键值？
     一是保证一致性，更新数据的时候只需要更新主键索引树，
     二是节省存储空间。
 为什么推荐InnoDB表必须有主键？
     保证会有主键索引树的存在（因为数据存放在主键索引树上面），如果没有mysql会自己生成一个rowid作为自增的主键主键索引
 为什么推荐使用整型的自增主键？
 	一是方便查找比较，
 	二是新增数据的时候只需要在最后加入，不会大规模调整树结构，如果是UUID的话，大小不好比较，新增的时候也极有可能在中间插入数据，会导致树结构大规调整，造成插入数据变慢。

## 分布式

##### 一致性hash

传统求余做[负载均衡](https://so.csdn.net/so/search?q=%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1&spm=1001.2101.3001.7020)算法，缓存节点数由3个变成4个，缓存不命中率为75%。计算方法：穷举hash值为1-12的12个数字分别对3和4取模，然后比较发现只有前3个缓存节点对应结果和之前相同，所以有75%的节点缓存会失效，可能会引起缓存雪崩。 

采用翻倍扩容，避免数据映射全部打乱而全部迁移，翻倍迁移只发生50%的数据迁移 

一致性hash算法 加入和删除节点只影响哈希环中顺时针方向的相邻的节点，对其他节点无影响。 

数据的分布和节点的位置有关，因为这些节点不是均匀的分布在哈希环上的，所以数据在进行存储时达不到均匀分布的效果。所以，出现了增加虚拟节点的方式来减少不均衡的现象。 

![1668565197884](C:\Users\haidong.wu\AppData\Local\Temp\1668565197884.png)

所以采用红黑树是最稳妥的实现方法。Java中直接使用TreeMap即可。 

--https://blog.csdn.net/gonghaiyu/article/details/108375298

##### 最终一致性方式解决 

1. 状态机实现幂等：即关注点是状态是否发生变化，若已经是更新后的状态，那么再收到调用请求也不做更新

2. 数据库唯一约束实现幂等

3. 通过tokenid的方式去识别每次请求判断是否重复

   TCC两阶段补偿方案

   TCC是Try-Conﬁrm-Cancel， 比如在支付场景中，先冻结一笔资金，再去发起支付。如果支付成功，则将冻结资金进行实际扣除；如果支付失败，则取消资金冻结

   - Try阶段：完成所有业务检查（一致性），预留业务资源（准隔离性）
   - Conﬁrm阶段：确认执行业务操作，不做任何业务检查，只使用Try阶段 预留的业务资源。
   - Cancel阶段：取消Try阶段预留的业务资源。Try阶段出现异常时，取消所有业务资源预留请求

##### Hystrix断路器原理及实现（服务降级、熔断、限流）

*熔断*的*实现原理*简单说来就是在一个设定的窗口时间内,根据设置的具体*熔断*策略,判断相应的计数统计是否超过了门限值,如果超过了则会触发*熔断*机制。 

**服务雪崩** ：微服务调用链中某个服务挂了

一、服务降级（fallback）

1、当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝），向调用方返回一个符合预期的、可处理的预备响应（FallBack），而不是长时间等待或者抛出调用方无法处理的异常。比如：服务繁忙，请稍后再试，不让客户端等待并立刻返回一个友好提示：fallback。

2、哪些情况会触发降级
（1）程序运行异常
（2）超时
（3）服务熔断触发服务降级
（4）线程池/信号量打满也会导致服务降级

二、服务熔断（break）

1、系统发到最大服务访问量后，直接拒绝访问，限制后续的服务访问，并调用服务降级方法返回友好提示。
2、就是保险丝：服务降级–>进而熔断–>恢复调用链路

三、服务限流（flowlimit）

1、限流的目的是为了保护系统不被大量请求冲垮，通过限制请求的速度来保护系统。在电商的秒杀活动中，限流是必不可少的一个环节。限制高并发，请求进行排队，一秒处理N个请求，有序的进行。
————————————————
原文链接：https://blog.csdn.net/qq_36763419/article/details/120119872

## 高并发

秒杀系统设计

解决高并发的方法主要有：系统拆分，缓存，MQ, 还有分库分表，读写分离等也是分而治之的思想。 

RabbitMq的消息队列除了有解耦和异步的功能外，还可以实现流量削峰 

## JDK

HashMap

多线程 

内存结构 JMM https://www.jianshu.com/p/76959115d486

volatile

```
由于现代操作系统都是多处理器操作系统，每个处理器都会有自己的缓存，可能存再不同处理器缓存不一致的问题，而且由于操作系统可能存在重排序，导致读取到错误的数据，因此，操作系统提供了一些内存屏障以解决这种问题.
简单来说:
1.在不同CPU执行的不同线程对同一个变量的缓存值不同，为了解决这个问题。
2.用volatile可以解决上面的问题，不同硬件对内存屏障的实现方式不一样。java屏蔽掉这些差异，通过jvm生成内存屏障的指令。
对于读屏障:在指令前插入读屏障，可以让高速缓存中的数据失效，强制从主内存取。
```

Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。

java内存结构：

![img](https://upload-images.jianshu.io/upload_images/10006199-a4108d8fb7810a71.jpeg?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp) 

程序计数器是一块很小的内存空间，它是线程私有的，可以认作为当前线程的行号指示器。

**每个方法被执行的时候都会创建一个栈帧用于存储局部变量表，操作栈，动态链接，方法出口等信息** 

Java虚拟机栈可能出现两种类型的异常：

1. 线程请求的栈深度大于虚拟机允许的栈深度，将抛出StackOverflowError。
2. 虚拟机栈空间可以动态扩展，当动态扩展是无法申请到足够的空间时，抛出OutOfMemory异常。

 方法区 用于存储已被虚拟机加载的类信息、常量、静态变量，如static修饰的变量加载类的时候就被加载到方法区中。 运行时常量池是方法区的一部分，class文件除了有类的字段、接口、方法等描述信息之外，还有常量池用于存放编译期间生成的各种字面量和符号引用。



```
对象在内存中存储的布局分为 ：
1.对象头 markword
2.实例数据
3.对齐填充
```

![img](https://upload-images.jianshu.io/upload_images/10006199-318ad80ccb29abe4.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp) 

并发包



对象头结构

一个类的大小计算

## JVM调优

工具步骤



## 类加载

过程 自定义类加载器

https://baijiahao.baidu.com/s?id=1675804610811644518&wfr=spider&for=pc

![img](https://pics1.baidu.com/feed/6f061d950a7b020873653dcada5cd9d4562cc8fd.jpeg@f_auto?token=0c68fa898abec150f15a566e5de4a299) 

加载阶段完成之后，虚拟机就会把外部的二进制字节流（不论从何处获取的）按照一定的数据格式存储在运行时数据区中的方法区。然后在内存中实例化一个java.lang.Class对象 

验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求 

准备阶段是类变量分配内存并设置初始值的阶段。这里的类变量指的是被static修饰的变量，而不包括实例变量。类变量被分配到方法区中，而实例变量存放在堆中。 如果变量被static 和 final同时修饰，则准备阶段直接赋值为指定值。 

解析阶段是将常量池中的符号引用转换为直接引用的过程。解析动作主要针对类或接口、字段、类方法、接口方法、方法属性、方法句柄、调用点限定符7类符号引用。 

初始化阶段是执行类构造器 < clinit > 方法的过程。

首先说下类构造器 < clinit > 方法和实例构造器 < init > 方法有什么区别。< clinit > 方法是在类加载的初始化阶段执行，是对静态变量、静态代码块进行的初始化。而< init > 方法是new一个对象，即调用类的 constructor方法时才会执行，是对非静态变量进行的初始化。

使用new关键词创建对象时，访问某个类的静态变量或给静态变量赋值时，调用类的静态方法时。反射调用时，会触发类的初始化（如Class.forName()）初始化一个类的时候，如其父类未初始化，则会先触发父类的初始化。虚拟机启动时，会先初始化主类（即包含main方法的类）。另外，也有些场景并不会触发类的初始化：

通过子类调用父类的静态变量，只会触发父类的初始化，而不会触发子类的初始化（因为，对于静态变量，只有直接定义这个变量的类才会初始化）。通过数组来创建对象不会触发此类的初始化。（如定义一个自定义的Person[] 数组，不会触发Person类的初始化）通过调用静态常量（即static final修饰的变量），并不会触发此类的初始化。因为，在编译阶段，就已经把final修饰的变量放到常量池中了，本质上并没有直接引用到定义常量的类，因此不会触发类的初始化。

## 垃圾回收

内存结构 算法 时机 类型

可达性分析算法帮我们解决了哪些对象可以回收的问题 

垃圾收集算法则关心怎么回收 

```
Java堆是GC回收的“重点区域”。堆中基本存放着所有对象实例，gc进行回收前，第一件事就是确认哪些对象存活，哪些死去[即不可能再被引用]
为了高效的回收，jvm将堆分为三个区域
1.新生代（Young Generation）NewSize和MaxNewSize分别可以控制年轻代的初始大小和最大的大小
2.老年代（Old Generation）
3.永久代（Permanent Generation）【1.8以后采用元空间，就不在堆中了】

可作为GC Roots的对象有四种
①虚拟机栈(栈桢中的本地变量表)中的引用的对象。
②方法区中的类静态属性引用的对象，一般指被static修饰引用的对象，加载类的时候就加载到内存中。
③方法区中的常量引用的对象,
④本地方法栈中JNI（native方法)引用的对象
要真正宣告对象死亡需经过两个过程。
1.可达性分析后没有发现引用链
2.查看对象是否有finalize方法，如果有重写且在方法内完成自救[比如再建立引用]，还是可以抢救一下，注意这边一个类的finalize只执行一次，这就会出现一样的代码第一次自救成功第二次失败的情况。[如果类重写finalize且还没调用过，会将这个对象放到一个叫做F-Queue的序列里，这边finalize不承诺一定会执行，这么做是因为如果里面死循环的话可能会时F-Queue队列处于等待，严重会导致内存崩溃，这是我们不希望看到的。]
GC是怎么判断对象是被标记的？通过枚举根节点的方式，通过jvm提供的一种oopMap的数据结构
```

![img](https://upload-images.jianshu.io/upload_images/10006199-854e1de91f66764b.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp) 

```
1.标记/清除算法【最基础】
2.复制算法
3.标记/整理算法
jvm采用`分代收集算法`对不同区域采用不同的回收算法。
新生代采用复制算法：将内存分为一块Eden空间和From Survivor、To Survivor【保留空间】，三者默认比例为8:1:1，优先使用Eden区，若Eden区满，则将对象复制到第二块内存区上。但是不能保证每次回收都只有不多于10%的对象存货，所以Survivor区不够的话，则会依赖老年代年存进行分配
 GC开始时，对象只会存于Eden和From Survivor区域，To Survivor【保留空间】为空。
GC进行时，Eden区所有存活的对象都被复制到To Survivor区，而From Survivor区中，仍存活的对象会根据它们的年龄值决定去向，年龄值达到年龄阈值(默认15是因为对象头中年龄战4bit，新生代每熬过一次垃圾回收，年龄+1)，则移到老年代，没有达到则复制到To Survivor。
老年代采用标记/清除算法或标记/整理算法
由于老年代存活率高，没有额外空间给他做担保，必须使用这两种算法。
```

G1(garbage first:尽可能多收垃圾，避免full gc)收集器是当前最为前沿的收集器之一(1.7以后才开始有)，同cms一样也是关注降低延迟，是用于替代cms（CMS采用的是"标记-清除"(Mark Sweep)算法，而且是支持并发(Concurrent)的 ）功能更为强大的新型收集器，因为它解决了cms产生空间碎片等一系列缺陷。

 g1通过并发(并行)标记阶段查找老年代存活对象，通过并行复制压缩存活对象【这样可以省出连续空间供大对象使用】。

g1将一组或多组区域中存活对象以增量并行的方式复制到不同区域进行压缩，从而减少堆碎片，目标是尽可能多回收堆空间【垃圾优先】，且尽可能不超出暂停目标以达到低延迟的目的。

 Minor GC、Major GC、FULL GC、mixed gc

stop the world简单来说就是gc的时候，停掉除gc外的java线程。 

新生代什么样的情况会晋升为老年代？

对象优先分配在eden区，eden区满时会触发一次minor GC

> 对象晋升规则
>  1 长期存活的对象进入老年代，对象每熬过一次GC年龄+1(默认年龄阈值15，可配置)。
>  2 对象太大新生代无法容纳则会分配到老年代
>  3 eden区满了，进行minor gc后，eden和一个survivor区仍然存活的对象无法放到(to survivor区)则会通过分配担保机制放到老年代，这种情况一般是minor gc后新生代存活的对象太多。
>  4 动态年龄判定，为了使内存分配更灵活，jvm不一定要求对象年龄达到MaxTenuringThreshold(15)才晋升为老年代，若survior区相同年龄对象总大小大于survior区空间的一半，则大于等于这个年龄的对象将会在minor gc时移到老年代

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy83eUdpYlRNTE1oWFBmZ0s0aWFpYmNpYlJtZ1NOTVA3SVdBRmliaWNKN3k5amZqMlk0S1hxZ1A2M3V6aWNIamRHWlA3dXZrSVo2SUtERkZMeVJpYnNJSHVJQkZRZ2VBLzY0MA?x-oss-process=image/format,png) 

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy83eUdpYlRNTE1oWFBmZ0s0aWFpYmNpYlJtZ1NOTVA3SVdBRmliWmtSZU9PY3FXSVgxdkZ0RkJaeHI4bEE5U0ZqWVlwRzV5Q0Z1cG90bHZnZzVpY2xjRmljdjJqWUEvNjQw?x-oss-process=image/format,png) 

```
-Xms20m -Xmx20m -Xmn10m -XX:SurvivorRatio=8 -XX:+PrintGCDetails
```

##  内存泄漏

现象：1.oom、2.有些场景下还会看到频繁执行full GC ，垃圾回收后，内存并没有减少多少 3.性能下降，莫名崩溃，接口调用失败

jconsole：本地启动后查看内存增长情况，点击执行GC后发现内存没有回收

idea连接方式：添加vm配置，然后启动main方法后，启动jconsole用远程连接127.0.0.1:8888,

```
-Djava.rmi.server.hostname=127.0.0.1
-Dcom.sun.management.jmxremote
-Dcom.sun.management.jmxremote.port=8888
-Dcom.sun.management.jmxremote.ssl=false
-Dcom.sun.management.jmxremote.authenticate=false
```

生产问题可以分析dump文件

思路：查找哪个对象的个数和占有空间再持续上升，特别是还发生过GC以后；查询是否有大量的线程出现

IDEA中内存分析工具—JProfiler插件

场景：

1.静态属性导致内存泄露
2.未关闭的资源
无论什么时候当我们创建一个连接或打开一个流，JVM都会分配内存给这些资源。比如，数据库链接、输入流和session对象。
如果进行处理呢?第一，始终记得在finally中进行资源的关闭;第二，关闭连接的自身代码不能发生异常;第三，Java7以上版本可使用try-with-resources代码方式进行资源关闭。
3.不当的equals方法和hashCode方法实现
4.使用ThreadLocal
第一，使用ThreadLocal提供的remove方法，可对当前线程中的value值进行移除;
第二，不要使用ThreadLocal.set(null) 的方式清除value，它实际上并没有清除值，而是查找与当前线程关联的Map并将键值对分别设置为当前线程和null。
第三，最好将ThreadLocal视为需要在finally块中关闭的资源，以确保即使在发生异常的情况下也始终关闭该资源。
5.finalize()方法,并且重写的方法在执行时需要一些时间。
6.外部类引用内部类;如果内部类不需要访问外部类的成员信息，可以考虑将其转换为静态内部类。

7.大量线程不能结束导致，比如FutureTask，线程池拒绝策略没有抛异常，后边用到FutureTask.get一直阻塞。

##  springboot

```
自动装配原理：通过3个注解
@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),
		@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })
public @interface SpringBootApplication {

@SpringBootConfiguration 注解标记启动类为配置类
@ComponentScan 注解实现启动时扫描启动类所在的包以及子包下所有标记为bean的类由IOC容器注册为bean
@EnableAutoConfiguration通过 @Import 注解导入 AutoConfigurationImportSelector类，然后通过AutoConfigurationImportSelector 类的 selectImports 方法去读取需要被自动装配的组件依赖下的spring.factories文件配置的组件的类全名，并按照一定的规则过滤掉不符合要求的组件的类全名，将剩余读取到的各个组件的类全名集合返回给IOC容器并将这些组件注册为bean
————————————————
@Import(AutoConfigurationImportSelector.class)

```



## 基本算法

## 设计模式

## GIT

#### 一台电脑（终端）可以配置多个 SSH-Key 用于多个 Git 账号。

换个名称即可，见1.其他的好像没用。 

```
1.ssh-keygen -t rsa -C '[邮箱]' -f ~/.ssh/github_id_rsa
ssh-keygen -t rsa -C '[邮箱]' -f ~/.ssh/gitlab_id_rsa
2.新建config并配置： touch config 、vim config，内容如下：
# github
Host github.com
HostName github.com
PreferredAuthentications publickey
IdentityFile ~/.ssh/github_id_rsa
# gitlab
Host gitlab.com
HostName gitlab.com
PreferredAuthentications publickey
IdentityFile ~/.ssh/gitlab_id_rsa
# 如果生成多个 SSH-Key , 则按上面的格式继续往下写
3.前往 ~/.ssh/ 目录下查看生成的文件：cat [xxx]_rsa.pub
4. 在 Github 或其他 Git 服务器新建 SSH Key，输入文本即可。
```

sourcetree：指定忽略文件，设置->高级:

```
*.iws
*.iml
*.ipr
target/
.settings
.project
.classpath
.externalToolBuilders
*.class
*svn/
.idea/
*.jar
~*
```



#### git命令



## Redis

作用：

1. 缓存

2. 数据共享分布式，如应用共享session

3. 全局ID

   int类型，incrby，利用原子性

   `incrby userid 1000`

   [分库分表](https://so.csdn.net/so/search?q=%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8&spm=1001.2101.3001.7020)的场景，一次性拿一段

   5、计数器

   int类型，incr方法

   例如：文章的阅读量、微博点赞数、允许一定的延迟，先写入Redis再定时同步到数据库

   计数功能应该是最适合 Redis 的使用场景之一了，因为它高频率读写的特征可以完全发挥 Redis 作为内存数据库的高效。在 Redis 的数据结构中，string、hash和sorted set都提供了incr方法用于原子性的自增操作，下面举例说明一下它们各自的使用场景：

   如果应用需要显示每天的注册用户数，便可以使用string作为计数器，设定一个名为REGISTERED_COUNT_TODAY的 key，并在初始化时给它设置一个到凌晨 0 点的过期时间，每当用户注册成功后便使用incr命令使该 key 增长 1，同时当每天凌晨 0 点后，这个计数器都会因为 key 过期使值清零。
   每条微博都有点赞数、评论数、转发数和浏览数四条属性，这时用hash进行计数会更好，将该计数器的 key 设为weibo:weibo_id，hash的 field 为like_number、comment_number、forward_number和view_number，在对应操作后通过hincrby使hash 中的 field 自增。
   如果应用有一个发帖排行榜的功能，便选择sorted set吧，将集合的 key 设为POST_RANK。当用户发帖后，使用zincrby将该用户 id 的 score 增长 1。sorted set会重新进行排序，用户所在排行榜的位置也就会得到实时的更新。
   ————————————————
   原文链接：https://blog.csdn.net/m0_67393593/article/details/125241392

   **点赞、签到、打卡**

   假如上面的微博ID是t1001，用户ID是u3001

   用 like:t1001 来维护 t1001 这条微博的所有点赞用户

   点赞了这条微博：sadd like:t1001 u3001
   取消点赞：srem like:t1001 u3001
   是否点赞：sismember like:t1001 u3001
   点赞的所有用户：smembers like:t1001
   点赞数：scard like:t1001

   **好友关系、用户关注**

   通过`set`解决 交集、差集问题

   ```
   举例
   follow 关注 fans 粉丝
   
   相互关注：
   
   sadd 1:follow 2
   sadd 2:fans 1
   sadd 1:fans 2
   sadd 2:follow 1
   我关注的人也关注了他(取交集)：
   
   sinter 1:follow 2:fans
   可能认识的人：
   
   用户1可能认识的人(差集)：sdiff 2:follow 1:follow
   用户2可能认识的人：sdiff 1:follow 2:follow 
   ```

   **维护商品标签，类似set**

   - sadd tags:i5001 画面清晰细腻；  sadd tags:i5001 真彩清晰显示屏

   - ```
     SMEMBERS somekey  #查看所有元素
     ```

4. 分布式锁：set lock_key locked NX EX 1  ，如果这个操作返回false，说明 key 的添加不成功，也就是当前有人在占用这把锁。而如果返回true，则说明得了锁，便可以继续进行操作，并且在操作后通过del命令释放掉锁。并且即使程序因为某些原因并没有释放锁，由于设置了过期时间，该锁也会在 1 秒后自动释放，不会影响到其他程序的运行。 

   推荐使用 redisson 第三方库实现分布式锁。 

   https://blog.csdn.net/agonie201218/article/details/121423212





1.KEYS pattern 查找所有匹配给定的模式的键,keys * 查看所有缓存的键

2.DEL key1 key2 删除指定的缓存(一个或多个)，get key //读取  set key value // 写入 

3.自增：

+ incr key // 键值加1 + decr key // 键值减1 + incrby key amount // 键值加amount + decrby key amount // 键值减amount + incrbyfloat key amount // 键值加上浮点数amount 

4.二进制位：

+ setbit key offset value //把指定的bit位设置为value(value只能是0或1) 

+ getbit key offset //获取指定bit位的二进制的值 

  

## 并发编程源码分析

syncronize 底层原理

volitile 底层原理

锁：公平锁和非公平锁实现原理？可重入锁实现原理？共享锁和排他锁的实现原理？

AQS？state机制

线程池

FutureTask、ExecutorCompletionService

线程通信

阻塞队列

工具类：信号量、降锁、栅栏、



### 队列

LinkedBlockingQueue中的锁是分离的，生产者的锁PutLock，消费者的锁takeLock，提高了线程并发执行的效率 ；内部维护的是一个链表结构 ；一般使用指定长度，若设置为无界队列，队列自身占用很大的内存，容易出现OOM 

而ArrayBlockingQueue生产者和消费者使用的是同一把锁；内部维护了一个数组 

相同点：都是通过ReentrantLock及condition通知机制来实现可阻塞式插入和删除元素并满足线程安全的特性； 

默认非公平take，公平队列也可以实现方式：lock = new ReentrantLock(fair);

### 应用场景

1. 报表 批量任务，多线程并行执行
2. 线程池的队列做限流
3. 阻塞队列应用再日志系统，生产者消费者模式

### 并发的三种场景

#### 分工

多线程并发最基本的场景就是分工。分工，就是线程各司其职，完成不同的工作。分工，也是有很多模式的。比如有:

- 生产者-消费者模式，大厨做饭，我们来吃；
- MapReduce模式，把工作拆分成多份，多个线程共同完成后，再组合结果，Java8中的stream与Fork/Join就是这种模式的体现；
- Thread-Per-Message模式，服务端就是这种模式，收到消息给不同的Thread进行处理；
- ... ...

#### 同步

有分工就要有同步，不同工人之间要协作，不同线程也是。一个线程的执行条件往往依赖于另一线程的执行结果。

线程之间最基本的通信机制是管程模式与wait/notify,除此外还有多个工具类，如：

- Future及其衍生的工具类FutureTask/CompletableFuture等，可以完成异步编程；

- CountDownLatch/CyclicBarrier可以实现特定场景的协作；

- Semaphore提供了经典的PV同步原语（p操作和v操作是不可中断的程序段，称为原语。P,V原语中P是荷兰语的Passeren，相当于英文的pass, V是荷兰语的Verhoog,相当于英文中的incremnet。 

  还可以作为限流器使用；

- ReentrantLock与Condtion,对管程同步的扩展；

- ... ...

#### 互斥

不同工人，操作相同的共享资源，就有可能冲突。类似，多线程访问相同的共享变量，就需要做互斥处理。分工与协作强调的是性能，互斥问题强调的是正确，即线程安全问题。Java解决互斥问题提供了很多思路与工具。

- 避免共享，没有共享，没有竞态，就没有伤害，如ThreadLocal；
- 没有改变，如果大家都不做改变，都是只读的，一起也没有错；
- Copy-on-write，你变你的，我变我的，每变一次都生成新的副本，只要不冲突就可以并行；
- CAS，写入前要看一看，有没有物逝人非（变量和自己读取时一样），没有再写入，否则再做一变；
- Lock，最终手段，但也不想做得太绝，够用就行，ReadWriteLock/StampedLock，够用就行；

互斥问题很像数据库，都是一样的。天下的互斥都是一样的。

## AC架构师

## 简历准备



